{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "828b7613-b4a9-453a-ab6c-4375c4429a5b",
   "metadata": {},
   "source": [
    "# Présentation de l'optimizer ADAM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea60bc56-90cc-4311-981e-ac050d6e5e6b",
   "metadata": {},
   "source": [
    "## Adam Adaptive Moment Estimation\n",
    "\n",
    "Adam optimizer est la version étendue de la descente de gradient stochastique qui pourrait être implémentée dans diverses applications d’apprentissage profond telles que la vision par ordinateur et le traitement du langage naturel. Adam a été présenté pour la première fois en 2014. Il a été présenté pour la première fois lors d’une célèbre conférence pour les chercheurs en apprentissage profond appelée ICLR 2015. \n",
    "\n",
    "L’optimiseur est appelé Adam car il utilise des estimations des premier et deuxième moments du gradient pour adapter le taux d’apprentissage à chaque poids du réseau neuronal.\n",
    "\n",
    "Avant Adam, de nombreuses techniques d’optimisation adaptative ont été introduites telles que AdaGrad, RMSP qui ont de bonnes performances par rapport à SGD mais dans certains cas présentent certains inconvénients tels que la généralisation des performances qui sont pires que celles du SGD dans certains cas. Donc, Adam a été introduit, ce qui est mieux en termes de généralisation de la performance. \n",
    "\n",
    "Toujours dans Adam, les hyperparamètres ont des interprétations intuitives et nécessitent donc moins d’accordage. \n",
    "\n",
    "Adam performe bien. Mais dans certains cas, les chercheurs ont observé qu’Adam ne converge pas vers la solution optimale, l’optimiseur SGD le fait à la place. Dans un ensemble diversifié de tâches d’apprentissage en profondeur, les optimiseurs Adam ont parfois de faibles performances de généralisation. Selon l’auteur Nitish Shirish Keskar et Richard Socher, le passage à SGD dans certains cas montre une meilleure performance de généralisation qu’Adam seul"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fda6a940",
   "metadata": {},
   "source": [
    "## Fonctionnement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ef3452f",
   "metadata": {},
   "source": [
    "Adam utilise une combinaison de techniques pour trouver la meilleure configuration de poids :\n",
    "\n",
    "- Tout d'abord, Adam maintient un taux d'apprentissage adaptatif pour chaque poids. Cela signifie qu'il ajuste automatiquement la taille des pas pour mettre à jour chaque poids. Certains poids peuvent nécessiter de plus petits pas, tandis que d'autres peuvent nécessiter de plus grands pas.\n",
    "\n",
    "- Adam utilise des estimations du premier et du second moment des gradients pour ajuster les taux d'apprentissage. Les gradients représentent les indications sur la direction dans laquelle vous devez ajuster les poids. Les estimations du premier moment indiquent comment les gradients changent au fil du temps, tandis que les estimations du second moment indiquent à quel point les gradients varient.\n",
    "\n",
    "- En utilisant ces estimations, Adam effectue des mises à jour des poids en ajustant les taux d'apprentissage pour chaque poids individuel. Cela permet de prendre en compte la nature spécifique de chaque poids lors de la mise à jour.\n",
    "\n",
    "L'avantage d'Adam est qu'il permet une convergence plus rapide de l'entraînement du modèle. Il est efficace pour les problèmes avec des données de grande dimension ou des fonctions coûts complexes.\n",
    "\n",
    "En résumé, l'optimiseur Adam est un algorithme qui permet d'ajuster les poids d'un modèle de manière intelligente en utilisant des taux d'apprentissage adaptatifs et des estimations des gradients. Cela permet de trouver plus rapidement la meilleure configuration de poids pour un modèle d'apprentissage automatique.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fc94a7b-ec0e-4c4b-ae66-a8e9224b9b68",
   "metadata": {},
   "source": [
    "### Essaie d'utilisation de Adam sur le dataset Breast_Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "91f5cdc1-7be2-4e36-b3e2-60a69bea9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9f97cf41-6323-495c-8ece-d92e082ea4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data from sklearn\n",
    "breast_cancer_dataset = sklearn.datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e68737c5-4af4-4f6e-bf60-b6a07e40c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data to a data frame\n",
    "data_frame = pd.DataFrame(breast_cancer_dataset.data, columns = breast_cancer_dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a87e6de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness   \n",
       "0        17.99         10.38          122.80     1001.0          0.11840  \\\n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry   \n",
       "0           0.27760          0.3001              0.14710         0.2419  \\\n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter   \n",
       "0                 0.07871  ...         25.38          17.33           184.60  \\\n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity   \n",
       "0      2019.0            0.1622             0.6656           0.7119  \\\n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 rows of the dataframe\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e4a3b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the 'target' column to the data frame\n",
    "data_frame['label'] = breast_cancer_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8f13d19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    357\n",
       "0    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of Target Varibale\n",
    "data_frame['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "494e045e",
   "metadata": {},
   "source": [
    "1 --> Benign\n",
    "\n",
    "0 --> Malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "aa4c551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating data\n",
    "\n",
    "X = data_frame.drop(columns='label', axis=1)\n",
    "Y = data_frame['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b5208a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "be144909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "34e7c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing tensorflow and Keras\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "837353a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the layers of Neural Network\n",
    "\n",
    "model = keras.Sequential([\n",
    "                          keras.layers.Flatten(input_shape=(30,)),\n",
    "                          keras.layers.Dense(20, activation='relu'),\n",
    "                          keras.layers.Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8fb1c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the layers of Neural Network\n",
    "\n",
    "# compiling the Neural Network\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8b08f1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 1s 22ms/step - loss: 0.6108 - accuracy: 0.6308 - val_loss: 0.4684 - val_accuracy: 0.7826\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.8215 - val_loss: 0.3408 - val_accuracy: 0.9783\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3463 - accuracy: 0.8900 - val_loss: 0.2638 - val_accuracy: 0.9783\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2815 - accuracy: 0.9218 - val_loss: 0.2116 - val_accuracy: 0.9783\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2333 - accuracy: 0.9364 - val_loss: 0.1768 - val_accuracy: 0.9783\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1995 - accuracy: 0.9462 - val_loss: 0.1530 - val_accuracy: 0.9783\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1750 - accuracy: 0.9511 - val_loss: 0.1363 - val_accuracy: 0.9783\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1559 - accuracy: 0.9584 - val_loss: 0.1244 - val_accuracy: 0.9783\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1413 - accuracy: 0.9609 - val_loss: 0.1153 - val_accuracy: 0.9783\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1294 - accuracy: 0.9682 - val_loss: 0.1090 - val_accuracy: 0.9783\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1206 - accuracy: 0.9731 - val_loss: 0.1036 - val_accuracy: 0.9783\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1123 - accuracy: 0.9780 - val_loss: 0.0994 - val_accuracy: 0.9783\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1056 - accuracy: 0.9804 - val_loss: 0.0958 - val_accuracy: 0.9783\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0999 - accuracy: 0.9804 - val_loss: 0.0927 - val_accuracy: 0.9783\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0949 - accuracy: 0.9804 - val_loss: 0.0900 - val_accuracy: 0.9783\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9804 - val_loss: 0.0882 - val_accuracy: 0.9783\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.9804 - val_loss: 0.0862 - val_accuracy: 0.9783\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9829 - val_loss: 0.0846 - val_accuracy: 0.9783\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9853 - val_loss: 0.0824 - val_accuracy: 0.9783\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9853 - val_loss: 0.0815 - val_accuracy: 0.9783\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9853 - val_loss: 0.0806 - val_accuracy: 0.9783\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9853 - val_loss: 0.0793 - val_accuracy: 0.9783\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.9853 - val_loss: 0.0786 - val_accuracy: 0.9783\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.9878 - val_loss: 0.0784 - val_accuracy: 0.9783\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.9878 - val_loss: 0.0777 - val_accuracy: 0.9783\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.9878 - val_loss: 0.0775 - val_accuracy: 0.9783\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9878 - val_loss: 0.0770 - val_accuracy: 0.9783\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9878 - val_loss: 0.0767 - val_accuracy: 0.9783\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.9878 - val_loss: 0.0762 - val_accuracy: 0.9783\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9878 - val_loss: 0.0758 - val_accuracy: 0.9783\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.9878 - val_loss: 0.0756 - val_accuracy: 0.9783\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.9878 - val_loss: 0.0751 - val_accuracy: 0.9783\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9878 - val_loss: 0.0751 - val_accuracy: 0.9783\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0540 - accuracy: 0.9878 - val_loss: 0.0746 - val_accuracy: 0.9783\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9878 - val_loss: 0.0746 - val_accuracy: 0.9783\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 0.9878 - val_loss: 0.0746 - val_accuracy: 0.9783\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9878 - val_loss: 0.0738 - val_accuracy: 0.9783\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9878 - val_loss: 0.0737 - val_accuracy: 0.9783\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0491 - accuracy: 0.9878 - val_loss: 0.0734 - val_accuracy: 0.9783\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9878 - val_loss: 0.0727 - val_accuracy: 0.9783\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0476 - accuracy: 0.9878 - val_loss: 0.0732 - val_accuracy: 0.9783\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9878 - val_loss: 0.0727 - val_accuracy: 0.9783\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9878 - val_loss: 0.0722 - val_accuracy: 0.9783\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 0.9902 - val_loss: 0.0719 - val_accuracy: 0.9783\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0443 - accuracy: 0.9902 - val_loss: 0.0710 - val_accuracy: 0.9783\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9902 - val_loss: 0.0714 - val_accuracy: 0.9783\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.9902 - val_loss: 0.0711 - val_accuracy: 0.9783\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9902 - val_loss: 0.0716 - val_accuracy: 0.9783\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0415 - accuracy: 0.9902 - val_loss: 0.0707 - val_accuracy: 0.9783\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9902 - val_loss: 0.0704 - val_accuracy: 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13fcbd890>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_std, Y_train, validation_split=0.1, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "beff37ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1056 - accuracy: 0.9649\n",
      "Accuracy :  0.9649122953414917\n",
      "Loss :  0.10563753545284271\n"
     ]
    }
   ],
   "source": [
    "loss_adam, accuracy_adam = model.evaluate(X_test_std, Y_test)\n",
    "print(\"Accuracy : \", accuracy_adam)\n",
    "print(\"Loss : \", loss_adam)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd9ff09c",
   "metadata": {},
   "source": [
    "# Comparaison Avec SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "03dc8ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "70645dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 0.0368 - accuracy: 0.9902 - val_loss: 0.0703 - val_accuracy: 0.9783\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0368 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0367 - accuracy: 0.9902 - val_loss: 0.0703 - val_accuracy: 0.9783\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0366 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0364 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0364 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0361 - accuracy: 0.9902 - val_loss: 0.0703 - val_accuracy: 0.9783\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0361 - accuracy: 0.9902 - val_loss: 0.0703 - val_accuracy: 0.9783\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0359 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 0.9902 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0358 - accuracy: 0.9902 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0357 - accuracy: 0.9902 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0357 - accuracy: 0.9902 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0355 - accuracy: 0.9902 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0355 - accuracy: 0.9902 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9902 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9902 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0353 - accuracy: 0.9927 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0353 - accuracy: 0.9902 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 0.9927 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9902 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0351 - accuracy: 0.9927 - val_loss: 0.0700 - val_accuracy: 0.9783\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 0.9927 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 0.9902 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9927 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9927 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0348 - accuracy: 0.9927 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0348 - accuracy: 0.9927 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.9927 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.9927 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9927 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0346 - accuracy: 0.9927 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9927 - val_loss: 0.0700 - val_accuracy: 0.9783\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 0.9927 - val_loss: 0.0700 - val_accuracy: 0.9783\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9927 - val_loss: 0.0700 - val_accuracy: 0.9783\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 0.9927 - val_loss: 0.0700 - val_accuracy: 0.9783\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 0.9927 - val_loss: 0.0700 - val_accuracy: 0.9783\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 0.9927 - val_loss: 0.0700 - val_accuracy: 0.9783\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0342 - accuracy: 0.9927 - val_loss: 0.0700 - val_accuracy: 0.9783\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0342 - accuracy: 0.9927 - val_loss: 0.0700 - val_accuracy: 0.9783\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.9927 - val_loss: 0.0700 - val_accuracy: 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ead2950>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_std, Y_train, validation_split=0.1, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d1d389c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.9649\n",
      "Accuracy :  0.9649122953414917\n",
      "Loss :  0.1078246459364891\n"
     ]
    }
   ],
   "source": [
    "loss_sgd, accuracy_sgd = model.evaluate(X_test_std, Y_test)\n",
    "print(\"Accuracy : \", accuracy_sgd)\n",
    "print(\"Loss : \", loss_sgd)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c20fe522",
   "metadata": {},
   "source": [
    "# Comparaison Avec rmsprop\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "22ffc1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 20ms/step - loss: 0.0360 - accuracy: 0.9927 - val_loss: 0.0716 - val_accuracy: 0.9783\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0340 - accuracy: 0.9927 - val_loss: 0.0713 - val_accuracy: 0.9783\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9927 - val_loss: 0.0719 - val_accuracy: 0.9783\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0326 - accuracy: 0.9927 - val_loss: 0.0703 - val_accuracy: 0.9783\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0318 - accuracy: 0.9927 - val_loss: 0.0703 - val_accuracy: 0.9783\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9927 - val_loss: 0.0706 - val_accuracy: 0.9783\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 0.9927 - val_loss: 0.0704 - val_accuracy: 0.9783\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0300 - accuracy: 0.9927 - val_loss: 0.0710 - val_accuracy: 0.9783\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 0.9927 - val_loss: 0.0699 - val_accuracy: 0.9783\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 0.9927 - val_loss: 0.0694 - val_accuracy: 0.9783\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9927 - val_loss: 0.0695 - val_accuracy: 0.9783\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 0.9927 - val_loss: 0.0694 - val_accuracy: 0.9783\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9927 - val_loss: 0.0708 - val_accuracy: 0.9783\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9927 - val_loss: 0.0695 - val_accuracy: 0.9783\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 0.9927 - val_loss: 0.0693 - val_accuracy: 0.9783\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9927 - val_loss: 0.0703 - val_accuracy: 0.9783\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9927 - val_loss: 0.0705 - val_accuracy: 0.9783\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.0697 - val_accuracy: 0.9783\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.0703 - val_accuracy: 0.9783\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.0714 - val_accuracy: 0.9783\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.0709 - val_accuracy: 0.9783\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.9951 - val_loss: 0.0719 - val_accuracy: 0.9783\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.0716 - val_accuracy: 0.9783\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9951 - val_loss: 0.0722 - val_accuracy: 0.9783\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0211 - accuracy: 0.9951 - val_loss: 0.0727 - val_accuracy: 0.9565\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0206 - accuracy: 0.9951 - val_loss: 0.0726 - val_accuracy: 0.9565\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0203 - accuracy: 0.9951 - val_loss: 0.0727 - val_accuracy: 0.9783\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0195 - accuracy: 0.9951 - val_loss: 0.0723 - val_accuracy: 0.9565\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0192 - accuracy: 0.9951 - val_loss: 0.0738 - val_accuracy: 0.9783\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.0738 - val_accuracy: 0.9565\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.0739 - val_accuracy: 0.9565\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.0754 - val_accuracy: 0.9565\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.0750 - val_accuracy: 0.9565\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.0760 - val_accuracy: 0.9565\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.0773 - val_accuracy: 0.9565\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.0765 - val_accuracy: 0.9565\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.0766 - val_accuracy: 0.9565\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0763 - val_accuracy: 0.9565\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0786 - val_accuracy: 0.9565\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.0775 - val_accuracy: 0.9565\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.0777 - val_accuracy: 0.9565\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.0772 - val_accuracy: 0.9565\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.0758 - val_accuracy: 0.9565\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.0773 - val_accuracy: 0.9565\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.0772 - val_accuracy: 0.9565\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0124 - accuracy: 0.9951 - val_loss: 0.0774 - val_accuracy: 0.9565\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0122 - accuracy: 0.9951 - val_loss: 0.0765 - val_accuracy: 0.9565\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.0778 - val_accuracy: 0.9565\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 0.9951 - val_loss: 0.0789 - val_accuracy: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ffc5550>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_std, Y_train, validation_split=0.1, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1ce88717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9649\n",
      "Accuracy :  0.9649122953414917\n",
      "Loss :  0.150255486369133\n"
     ]
    }
   ],
   "source": [
    "loss_rms, accuracy_rms = model.evaluate(X_test_std, Y_test)\n",
    "print(\"Accuracy : \", accuracy_rms)\n",
    "print(\"Loss : \", loss_rms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d5e4623",
   "metadata": {},
   "source": [
    "# ADAGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "06e95416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 19ms/step - loss: 0.0109 - accuracy: 0.9951 - val_loss: 0.0788 - val_accuracy: 0.9565\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0109 - accuracy: 0.9951 - val_loss: 0.0788 - val_accuracy: 0.9565\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0109 - accuracy: 0.9951 - val_loss: 0.0788 - val_accuracy: 0.9565\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0109 - accuracy: 0.9951 - val_loss: 0.0787 - val_accuracy: 0.9565\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0787 - val_accuracy: 0.9565\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0787 - val_accuracy: 0.9565\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0786 - val_accuracy: 0.9565\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0786 - val_accuracy: 0.9565\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0786 - val_accuracy: 0.9565\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0786 - val_accuracy: 0.9565\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0785 - val_accuracy: 0.9565\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0785 - val_accuracy: 0.9565\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0785 - val_accuracy: 0.9565\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0785 - val_accuracy: 0.9565\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0785 - val_accuracy: 0.9565\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0784 - val_accuracy: 0.9565\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0784 - val_accuracy: 0.9565\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0784 - val_accuracy: 0.9565\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0784 - val_accuracy: 0.9565\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.0783 - val_accuracy: 0.9565\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0783 - val_accuracy: 0.9565\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0783 - val_accuracy: 0.9565\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0783 - val_accuracy: 0.9565\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0783 - val_accuracy: 0.9565\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0783 - val_accuracy: 0.9565\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0782 - val_accuracy: 0.9565\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0782 - val_accuracy: 0.9565\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0782 - val_accuracy: 0.9565\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0782 - val_accuracy: 0.9565\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0782 - val_accuracy: 0.9565\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0781 - val_accuracy: 0.9565\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0781 - val_accuracy: 0.9565\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0781 - val_accuracy: 0.9565\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0781 - val_accuracy: 0.9565\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0781 - val_accuracy: 0.9565\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0781 - val_accuracy: 0.9565\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0781 - val_accuracy: 0.9565\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0780 - val_accuracy: 0.9565\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.0780 - val_accuracy: 0.9565\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0780 - val_accuracy: 0.9565\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0780 - val_accuracy: 0.9565\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0780 - val_accuracy: 0.9565\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0780 - val_accuracy: 0.9565\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14005ac50>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adagrad',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_std, Y_train, validation_split=0.1, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "959b35dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1527 - accuracy: 0.9649\n",
      "Accuracy :  0.9649122953414917\n",
      "Loss :  0.15267443656921387\n"
     ]
    }
   ],
   "source": [
    "loss_agrad, accuracy_agrad = model.evaluate(X_test_std, Y_test)\n",
    "print(\"Accuracy : \", accuracy_agrad)\n",
    "print(\"Loss : \", loss_agrad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b72d7f6",
   "metadata": {},
   "source": [
    "# ADELTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d1067ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 20ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.0779 - val_accuracy: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1401a8690>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adadelta',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_std, Y_train, validation_split=0.1, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4405f33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0235 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9649\n",
      "Accuracy :  0.9649122953414917\n",
      "Loss :  0.15276972949504852\n"
     ]
    }
   ],
   "source": [
    "loss_adelta, accuracy_adelta = model.evaluate(X_test_std, Y_test)\n",
    "print(\"Accuracy : \", accuracy_adelta)\n",
    "print(\"Loss : \", loss_adelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "65dff99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([1,0,1,0.80])\n",
    "algo=['accuracy_adam','accuracy_sgd','accuracy_rms','accuracy_agrad','accuracy_adelta', ]\n",
    "valeurs = [accuracy_adam,accuracy_sgd,accuracy_rms,accuracy_agrad,accuracy_adelta]\n",
    "ax.bar(algo,valeurs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b32da95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([1,0,1,0.80])\n",
    "algo=['loss_adam','loss_sgd','loss_rms','loss_agrad','loss_adelta', ]\n",
    "valeurs = [loss_adam,loss_sgd,loss_rms,loss_agrad,loss_adelta]\n",
    "ax.bar(algo,valeurs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4407f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgZAr7HWI0Q27aScz2yfPL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syllasn/Enseignements_UADB/blob/main/labs_MLP_UADB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_blobs"
      ],
      "metadata": {
        "id": "gW7d0B-VxNde"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,Y = make_blobs(n_samples=50, n_features=4, random_state=0,centers= 2)"
      ],
      "metadata": {
        "id": "zjFHgynxxYJZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# initialisation du model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#. 1 . input layer \n",
        "model.add(tf.keras.layers.Dense(3, input_dim= 4 , activation='relu'))\n",
        "#  2; Couche cachees\n",
        "model.add(tf.keras.layers.Dense(5,activation= 'sigmoid' ))\n",
        "model.add(tf.keras.layers.Dense(3,activation= 'sigmoid' ))\n",
        "\n",
        "# 3 / output layer\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "tVbNHLfsz-70"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2okixdlV3Reu",
        "outputId": "5147cc0c-5797-4da2-99ff-c98adaa5679b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 3)                 15        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 20        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 18        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57\n",
            "Trainable params: 57\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "1wFfpcwAIYhz",
        "outputId": "20ebeeea-9374-48f2-adf4-4a823c7e736f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASkAAAIECAIAAADKIU+gAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3deVxTV/4//nMTspMAIpssCkGlimvVEcSP9uOUGXUAFalxrfqxRWtLUXQoohQRtAxWKFQ/HZXyaLUVEHngUrBugzM+XGo/YqHwVQEVRIqgAgETFuH8/ri/3smwhCQmOQm+n3+Ze29Ozr03L3M3zpvCGCMAgNGxSHcAgNcUZA8AMiB7AJAB2QOADAvVF9euXdu3bx+prgAwuPn4+GzevJl5+R+/e48ePcrJyTF6lwahnJycmpoa0r0wiOvXr1+/fp10L8zP9evXr127pjrFovdCx48fN1Z/Bi2KojZt2vTOO++Q7oj+hYSEIPiSaI/ebqrgfA8AMiB7AJAB2QOADMgeAGRA9gAg41Wzt27dOrFYTFHU7du39dIhneXn51tZWZ0+fZpsN3Rm7v3vYf369dTvVqxYoTrrwoULUVFRJ06c8PDwoBdYuXKl6gL+/v5isZjNZo8dO/bWrVvG7fi/tbW1eXl5bd++HSF06tSpxMTErq4uZm5eXh6zgkOHDtWh/VfN3uHDhw8dOvSKjeiFuf9Bhrn3v7chQ4YUFBTcvXs3PT2dmfjpp5+mpqZu27YtODj4/v37UqnU1tb26NGjP/zwA7PMuXPnjh8/HhAQUFpaOnnyZBJ9Rwih6Ojou3fv0v8ODAzk8/lz5sxpamqipwQFBdXU1Pzzn/+cN2+ebu0PnmPO+fPnNzc3BwQEGKh9pVLp6+troMaR+fe/N4FA8Oc//3nUqFE8Ho+e8tlnn2VmZmZnZ4vFYmax1NRUFosVGhra3NxszO6pd/Xq1V9//VV1yscffzxhwoR58+a9fPkSIURRlLOz88yZM0eOHKnbR+ghexRFvXojpi89Pb2+vp50L3RHvP8VFRU7duzYuXMnn89Xne7r6xseHv748eMtW7aQ6lsPSqVy69atKSkpPabHxsbevn2793Td6JI9jHFSUtLo0aN5PJ6VldXWrVuZWV1dXTExMW5ubgKBYPz48VlZWQihAwcOiEQioVB48uTJuXPnSiQSFxeXY8eO0W+5fPnytGnThEKhRCIZN26cXC7vrx01rly54ubmRlHUl19+qf4TU1NT+Xy+vb39+vXrnZyc+Hy+r6/vjRs3EEJhYWFcLtfR0ZFuc+PGjSKRiKKop0+fhoeHR0REVFZWUhTl6empw0Yztf6fPXtWIpEkJCTofV36k5qaijEODAzsPSs+Pn7UqFGHDx++cOFC77kY43379r3xxhs8Hs/GxmbBggV37txBA32vtP0KqYqOjt64caOdnV2P6TY2NrNmzUpJSdHPCQJWQfcPDyQ6OpqiqM8//7yxsVGhUOzfvx8hVFRUhDHesmULj8fLyclpbGzctm0bi8W6efMm/RaE0MWLF5ubm+vr62fOnCkSiTo6OlpbWyUSSWJiolKprKurW7RoUUNDg5p21Hj06BFCKC0tjelkn5+IMQ4NDRWJRGVlZW1tbaWlpVOnThWLxdXV1Rjj5cuXOzg4MG0mJSUhhOguBQcHS6XSATcODSGUlZWl4cJE+n/mzBmxWBwXF6dVJzHGixcvXrx48YCLhYaGOjs7q07x8PAYM2ZMj8WkUumDBw8wxlevXmWxWCNGjGhtbcUYFxQUBAUF0cvExMRwudwjR440NTUVFxdPnjx56NChdXV16reSDl8h2pUrVwIDAzHGDQ0NdA5V50ZFRTHfdtrHH39sa2s7YLO9t5vWv3tKpTI5OfmPf/zj5s2bra2tBQLBkCFD6FltbW0HDhxYuHBhcHCwtbX19u3bORxORkYG815fX1+JRGJnZyeTyV68eFFdXf3w4UO5XD527Fg+n+/g4HDixImhQ4cO2I7men8iPd3CwoL+f3TMmDEHDhxoaWnRrX1DM1z/58+fL5fLd+zYYYBe9+HFixcPHjyQSqX9LeDj47Np06aHDx9+8sknqtOVSuW+ffsWLVq0YsUKKyurcePGffXVV0+fPj148CCzTO+tpPNXSKlUhoeHHzhwoL8F6LO7kpISjVZbLa2zV1FRoVAo5syZ03vW3bt3FQqFt7c3/VIgEDg6OtKHBz1wuVyEUGdnp4eHh729/YoVK2JjYx8+fKhtO5pjPrH3rClTpgiFwlds39DMvf/19fUYY6FQqGaZ+Pj40aNH79+//8qVK8zE0tLS1tbWKVOmMFOmTp3K5XLpw+wemK2k81do27Zt77//vrOzc38L0Kvw5MmTAZsakNbZo/80pvehMELoxYsXCKHt27cz9z2qqqoUCoWa1gQCwaVLl/z8/BISEjw8PGQymVKp1KGdV8Tj8egDDDNl+v1va2tDCDEXPPvE5/MzMjIoilq7dq1SqaQn0tf0LS0tVZe0trZuaWlR05RuX6ErV66UlJSsW7dOzTICgYBZnVekdfboi1Tt7e29Z9GBTE5OVj2o7fE3S72NHTv29OnTtbW1kZGRWVlZe/fu1a0dnXV2djY1Nbm4uBiofUMzi/7TX1nVe9N9ov+6tLy8fNeuXfQUa2trhFCPpA24vrp9hdLT0y9evMhisei40o0kJCRQFPXzzz/Ty3R0dDCr84q0zp63tzeLxbp8+XLvWa6urnw+X6sHXGpra8vKyhBCdnZ2e/bsmTx5cllZmQ7tvIrCwkKM8fTp0xFCFhYWfR7XmTKz6L+9vT1FUZrcwdu1a5eXl1dRURH90tvb29LSkvnqI4Ru3LjR0dHx5ptvqmlEt69QRkaGalZVr7UwB730Kjg4OGjVcp+0zp6dnV1wcHBOTk56erpcLi8uLmbOevl8/po1a44dO3bgwAG5XN7V1VVTU/Pbb7+paa22tnb9+vV37tzp6OgoKiqqqqqaPn26Du1oq7u7u7Gx8eXLl8XFxeHh4W5ubqtXr0YIeXp6Pn/+PC8vr7Ozs6GhoaqqinnLkCFDamtrHz582NLSQvz7/er9LygoMOY9BqFQ6OHhocnf8tNHnmw2m3kZERGRm5t79OhRuVxeUlKyYcMGJyen0NBQ9Y309xWSyWQODg46P6pGr8K4ceN0e/t/UA26hvcYWlpa1q1bZ2tra2lp6efnFxMTgxBycXH55Zdf2tvbIyMj3dzcLCws6JSWlpbu37+fPkMdOXJkZWXlwYMHJRIJQmj48OHnz5/39fW1sbFhs9nDhg2Ljo5++fIlxrjPdtR0KS0tjb6vJRQKAwMD1XzivXv3QkNDORyOs7OzhYWFRCJZsGBBZWUl3c6zZ8/eeustPp/v7u7+0Ucf0bcuPT09q6urb926NXz4cIFA4OfnR1/gVgNpeY/B+P3Pz88Xi8Xx8fGad5Km8z2GsLAwDoejUCjol7m5ufRlz6FDh3744Yc93r5161bmHkN3d3dSUtLIkSM5HI6Njc3ChQvv3r2LMVa/lfr7Ci1cuBAhFBMTM+Aq9HmPYf78+c7Ozt3d3cwUne8x6JI9cxcaGjpkyBCDfoS22dOKEfqvhs7ZKy8vt7CwOHLkiMG6ppGurq6ZM2emp6fr8N6nT5/y+fy9e/eqTjTe/b3BYcCTfhNnFv1XKpU//vhjeXk5fX3C09MzLi4uLi6utbWVVJe6urry8vJaWlpkMpkOb4+NjZ04cWJYWBhCCGNcW1t75cqViooK3TpjNtm7c+cO1T/dNiUwqOfPn9PPUq9du5aeEhUVFRISIpPJSD02XVhYeOLEiYKCAvV3Gvu0b9++27dv5+fnczgchNDJkyfpZ6lV/wJDO6o/gq/DMWdUVBR9B3bEiBHHjx830Kcggx1zGqf/amh4zKnGjz/+GBkZqa/+GEdeXt7u3bvpixG66b3dKKzyVGh2dvaSJUvwoPtDMuOjKCorKwvGCASM3tvNbI45ARhkIHsAkAHZA4AMyB4AZED2ACBE9aKnVn9XDwDQSo97DH3UIYIEvrolS5aEh4f7+PiQ7oj+JScnI4Q2bdpEuiNmht5uqvrI3qC8K2VkS5Ys8fHxGZRbkr5DNShXzaB63xGF8z0AyIDsAUAGZA8AMiB7AJAB2QOADN2zd/369TfeeIMe1MnBwSE+Pl6P3eqTatUoR0fHHpWlgEmBGmAD631vXau/SvrTn/6EEGpsbNTqXa9CKpVaWVkZ7eN0gww5ZgRZmo8ZwdQAa2trY6bHxMQEBATI5XL6JV0DDCF05swZ1berjglPyubNm5HKeC0pKSmzZs1ivurd3d1MDbDBOWaE8StXmTi9bBDjbFWoAaaeqWePeOUqU6OXDUJkq0INsB70mT1TqLz1r3/9a8yYMVZWVnw+f9y4cT/++CNCaN26dfRxuVQqpQddXbNmjVAotLKyOnXqVJ/Fov72t78JhUKxWFxfXx8REeHs7MyUINUX3E9pK803iHnVA4MaYH2sGOPVz/eMUHlL/fne8ePHY2Njnz9//uzZs+nTpzMH4sHBwWw2+/Hjx8ySy5YtO3XqFB6obtnHH3+clpa2aNGi//f//p/mmwVpcL6nprSV5hvE+PXAoAYYIlUDTBMEK28tXrz4008/tbGxGTJkSGBg4LNnz+gtuGHDhq6uLubj5HL5zZs3582bN2CxqM8+++zDDz88ceKEl5eXHvupSWkrDZlFPTCoAdabYc/3yFauosdyo68L//d///eoUaO+/vprjDFCKDMzUyaTsdlsQ9Qb04RWpa00Z7L1wKAGWG8kr7UYonLVDz/8MHv2bDs7Ox6P99e//pWZTlHU+vXr79+/f/HiRYTQt99++z//8z9I12JRr0630laaMM16YFADrDdi2dNv5ap//vOfycnJ1dXVCxcudHR0vHHjRnNzc2Jiouoyq1ev5vP5hw8fvnv3rkQiGT58ONK1WNSr06201YBMth4Y1ADrjVj29Fu56v/+7/9EIlFJSUlnZ+cHH3zg4eHB5/MpilJdxsbGZsmSJXl5eXv37n3vvffoiUauN8ZQX9pK5w1isvXAoAZYb0bNniEqb3V2dj558qSwsFAkErm5uSGELly40NbWVl5e3vuUYMOGDe3t7WfOnAkICKCnGKHeWJ/Ul7bSaoOYRT0wqAHWB9Wga3WP4fr162PHjmWxWAghR0fHhIQEQ1eu+t///V81F8pyc3MxxpGRkUOGDLG2tg4JCfnyyy8RQlKplL7mTps0aVJUVJTqivRZLCoxMZE+rnB1ddWhdA7S4B5Df6WtNN8gdXV1xq8HBjXAzK8GGNnKVYx58+bdv3/f0J+iSfb0wvhbFWqAmWUNMFKVq5iD1eLiYvp3gEg3DMRk64FBDTD1TP15Tr2IjIwsLy+/d+/emjVrmAtowNCgBtgAVH8EDXfMSbZyVXR0NIvFcnV1pR8iMwJklGNOIlsVaoDpBmqAGQnUAAM9QA0wAEwFZA8AMiB7AJAB2QOAjD7qMWRnZxu/H4OPER7IJoJ+qAq+JNqqqanp+fy36kVPqEAEgOGou8cAzMsgvpPxOoDzPQDIgOwBQAZkDwAyIHsAkAHZA4AMyB4AZED2ACADsgcAGZA9AMiA7AFABmQPADIgewCQAdkDgAzIHgBkQPYAIAOyBwAZkD0AyIDsAUAGZA8AMiB7AJAB2QOADMgeAGRA9gAgA7IHABmQPQDIgOwBQAZkDwAyIHsAkAHZA4AMyB4AZED2ACADsgcAGZA9AMjoo946MFmHDh16/vy56pSTJ08+ePCAeblmzRp7e3uj9wvoAmo+m5P169f//e9/5/F4vWd1dnba2NjU1dVZWMD/p+YBjjnNydKlSxFC7X1hs9nLli2D4JkR+N0zJxhjZ2fn3377rc+5V69e9fHxMXKXgM7gd8+cUBS1fPlyLpfbe9awYcOmT59u/C4BnUH2zMzSpUs7Ojp6TORyue+++y5FUUS6BHQDx5zmZ+TIkRUVFT0mFhcXjxs3jkh/gG7gd8/8rFixgsPhqE7x9PSE4JkdyJ75WbFixcuXL5mXHA5nzZo1BPsDdAPHnGZp4sSJxcXF9L6jKKqystLd3Z10p4B24HfPLK1atYrNZiOEKIp68803IXjmCLJnlpYuXdrd3Y0QYrPZq1atIt0doAvInllycnKaMWMGRVHd3d0hISGkuwN0AdkzVytXrsQYz54929HRkXRfgE6wgZFePwB0lJWVZdBoGOPR2/DwcHN/zvDatWspKSlZWVmkO/IfkpOT33//fZFI9IrtLFmyZBDsI/1asmSJwT/DoMnGGCPD//9hBHTqSPeip8ePH+ulncGxj/TLCNsEzvfM2LBhw0h3AegOsgcAGZA9AMiA7AFABmQPADJMNHvr1q0Ti8UURd2+fZt0X3SXn59vZWV1+vRp0h3RpwsXLkRFRZ04ccLDw4OiKIqiVq5cqbqAv7+/WCxms9ljx469desWqX62tbV5eXlt374dIXTq1KnExMSuri5SnemTiWbv8OHDhw4dIt2LV4UH3aMFn376aWpq6rZt24KDg+/fvy+VSm1tbY8ePfrDDz8wy5w7d+748eMBAQGlpaWTJ08m1dXo6Oi7d+/S/w4MDOTz+XPmzGlqaiLVn95MNHuDw/z585ubmwMCAgzUvlKp9PX1NVDjvX322WeZmZnZ2dlisZiZmJqaymKxQkNDm5ubjdaTAV29evXXX39VnfLxxx9PmDBh3rx5qn/6SJbpZg9GHxlQenp6fX29cT6roqJix44dO3fu5PP5qtN9fX3Dw8MfP368ZcsW4/RkQEqlcuvWrSkpKT2mx8bG3r59u/d0UkwoexjjpKSk0aNH83g8KyurrVu3MrO6urpiYmLc3NwEAsH48ePpp0wOHDggEomEQuHJkyfnzp0rkUhcXFyOHTtGv+Xy5cvTpk0TCoUSiWTcuHFyuby/dgzkypUrbm5uFEV9+eWX6nubmprK5/Pt7e3Xr1/v5OTE5/N9fX1v3LiBEAoLC+NyuczT0hs3bhSJRBRFPX36NDw8PCIiorKykqIoT09PhNDZs2clEklCQoIhVic1NRVjHBgY2HtWfHz8qFGjDh8+fOHChd5zMcb79u174403eDyejY3NggUL7ty5o36DoFfbU9HR0Rs3brSzs+sx3cbGZtasWSkpKaZyLmDQp2awNs/mREdHUxT1+eefNzY2KhSK/fv3I4SKioowxlu2bOHxeDk5OY2Njdu2bWOxWDdv3qTfghC6ePFic3NzfX39zJkzRSJRR0dHa2urRCJJTExUKpV1dXWLFi1qaGhQ086AdHum7NGjRwihtLQ0ZgX77C3GODQ0VCQSlZWVtbW1lZaWTp06VSwWV1dXY4yXL1/u4ODAtJmUlIQQolcnODhYKpUys86cOSMWi+Pi4rTtpyb7yMPDY8yYMT0mSqXSBw8eYIyvXr3KYrFGjBjR2tqKMS4oKAgKCqKXiYmJ4XK5R44caWpqKi4unjx58tChQ+vq6tRvEJ331JUrVwIDAzHGDQ0NCKHo6GjVuVFRUcyX6tW3ySsylewpFAqhUPj2228zU+j/AouKipRKpVAolMlkzJI8Hu+DDz7Av+88pVJJz6LjWlFRQR/rnzlzRvUj1LQzID1mr3dvMcahoaFWVlbMG2/evIkQ2rlzJ9YmezobcB+1trZSFBUQENBjOpM9jHFERARC6MMPP8Qq2VMoFJaWlsw2xxj/9NNPCCH6P4j+NojOe0qhUEyZMqWmpgb3k72vv/4aIfTtt98O2JQRsmcqx5wVFRUKhWLOnDm9Z929e1ehUHh7e9MvBQKBo6MjfdzSAz1obGdnp4eHh729/YoVK2JjYx8+fKhtO8bB9Lb3rClTpgiFQoJ966G+vh5jLBQK1SwTHx8/evTo/fv3X7lyhZlYWlra2to6ZcoUZsrUqVO5XC59RN0Ds0F03lPbtm17//33nZ2d+1uAXoUnT54M2JQRmEr2ampqEEK9j9ERQi9evEAIbd++nfpdVVWVQqFQ05pAILh06ZKfn19CQoKHh4dMJlMqlTq0QxCPx6P/5zYFbW1tCKE+a7Aw+Hx+RkYGRVFr165VKpX0RPqavqWlpeqS1tbWLS0taprSbU9duXKlpKRk3bp1apYRCATM6hBnKtmjr561t7f3nkUHMjk5WfX3+tq1a+obHDt27OnTp2trayMjI7Oysvbu3atbO0R0dnY2NTW5uLiQ7sj/j/7KDnhv2sfHZ/PmzeXl5bt27aKnWFtbI4R6JG3AVdNtT6Wnp1+8eJHFYtFxpRtJSEigKOrnn3+ml6GH9KZXhzhTyZ63tzeLxbp8+XLvWa6urnw+X6sHXGpra8vKyhBCdnZ2e/bsmTx5cllZmQ7tkFJYWIgxpusrWFhY9Hlcakz29vYURWlyB2/Xrl1eXl5FRUX0S29vb0tLS+arjxC6ceNGR0fHm2++qaYR3fZURkaGalZVz/eYg156FRwcHLRq2UBMJXt2dnbBwcE5OTnp6elyuby4uPjgwYP0LD6fv2bNmmPHjh04cEAul3d1ddXU1PRXi4dWW1u7fv36O3fudHR0FBUVVVVVTZ8+XYd2jKm7u7uxsfHly5fFxcXh4eFubm6rV69GCHl6ej5//jwvL6+zs7OhoaGqqop5y5AhQ2prax8+fNjS0tLZ2VlQUGCgewxCodDDw4M+L1CPPvKkxy+kX0ZEROTm5h49elQul5eUlGzYsMHJySk0NFR9I/3tKZlM5uDgoPOjavQqmMoY3oa5hPNvSOPrRS0tLevWrbO1tbW0tPTz84uJiUEIubi4/PLLL+3t7ZGRkW5ubhYWFnRKS0tL9+/fT586jxw5srKy8uDBgxKJBCE0fPjw8+fP+/r62tjYsNnsYcOGRUdHv3z5EmPcZzua9E2H65xpaWn0fTmhUBgYGKimt/fu3QsNDeVwOM7OzhYWFhKJZMGCBZWVlXQ7z549e+utt/h8vru7+0cffUTf9vT09Kyurr5169bw4cMFAoGfn19dXV1+fr5YLI6Pj9eqn1izfRQWFsbhcBQKBf0yNzdXKpUihIYOHUpf21S1detW5h5Dd3d3UlLSyJEjORyOjY3NwoUL7969izFWv0H621MLFy5ECMXExAy4Un1e55w/f76zs3N3d7detskrMqHsmTJDjxkRGho6ZMgQw7Wvnib7qLy83MLC4siRI8bpUn+6urpmzpyZnp6uw3ufPn3K5/P37t2rycJG+N6ayjEnMLWn7Hvw9PSMi4uLi4trbW0l1Yeurq68vLyWlhaZTKbD22NjYydOnBgWFqb3jukGsgc0FRUVFRISIpPJSD02XVhYeOLEiYKCAvV3Gvu0b9++27dv5+fn9yjhRBBkj7xt27ZlZGQ0Nze7u7vn5OSQ7o46CQkJYWFhe/bsIfLpc+bM+e6773QYC/jkyZPt7e2FhYU2NjaG6JhujDE+J1Bv9+7du3fvJt0LTfn7+/v7+5PuhXaCgoKCgoJI96In+N0DgAzIHgBkQPYAIAOyBwAZxrjWYprPK2uFXoXs7GzSHTGUQbCPzI9B79xjE/njfAC0Nxiea4Fnykzc4NhH+mWEXMD5HgBkQPYAIAOyBwAZkD0AyIDsAUAGZA8AMshnT7WaFI3L5drb28+ePTspKamxsZF0B8F/MOUaYImJiV5eXgKBQCQSeXl57dixg64FYJo1wExlzAipVEoPzEwPGfSPf/xj9erVFEU5OTlpOBi4QcH9PVpMTExAQIBcLqdf0jXAUK8hwFXHhDem+fPn7927t76+vqWlJTs7m8PhMCOdp6SkzJo1q7GxUcOmNN8mOiP/u9cDRVHW1tazZ8/OyMjIzs5+8uQJXUmLdL8MSC+lvIxQD8z0a4BxuVy6CoqlpWVISMiCBQvOnz9PD3AGNcC0s3jx4tWrV9fX13/11Vek+2JAeinlZeh6YGZRAyw3N1e1e/Tg8MwAM1ADTDv0GJUFBQXIHCqB4X7qXWleystk64GZUQ0wRnl5ubW19fDhw+mXUAOsb8z5Xg90WlxdXTHRSmAanu+pqXeleTkh49cD02QfmUsNMIxxR0dHTU1NWloaj8frMagh1ADrQ3/ZwxjTZ4BkK4Fpkj319a60yp6R64ENuI/MpQYYjR7y3dbW9osvvqCTzIAaYFp48eIFxlgikZh+JTCt6l1pzhTqgZlLDTDao0eP6uvrv//++2+++WbSpEmqp8FQA0wL9+7dQwh5eXmZfiUw3epdaYJ4PTCzqAHG4HA4dnZ2/v7+mZmZpaWlqmPAQQ0wLZw9exYhNHfuXNOvBKZbvasBmUI9MLOoAdabp6cnm80uLS1lpkANME3V1dUlJye7uLisXbvW9CuBqa93pXMpL1OoB2YWNcCePXu2bNky1Snl5eVdXV2urq7MFKgB1jeMcWtrK10jpqGhISsra8aMGWw2Oy8vTyKRmH4lMPX1rjQv5YVMrx6YWdQAE4lE586du3Tpklwu7+zsLCoqevfdd0Ui0ebNm5lloAbYfzh16tT48eOFQiGXy2WxWOj3R1umTZsWFxf37NkzZkmClcA0vMfQX70rrE0pL+PXAxtwH2EzqQEWGBjo7u5uaWnJ4/GkUqlMJispKVFdAGqAmR9jPs9p/HpgmuwjqAGmdyZ0zAkYJvfEPdQAMwDIHtAU1ADTL8ieaTHxemBQA0yPoAaYaTH9emBQA0xf4HcPADIgewCQAdkDgAzIHgBkGONaS3Jy8vHjx43wQYZDP4sUEhJCuiOGMgj2kdmhsIH/fn4Qf1+Ju3jxore3t4k8GTz4bN682cfHx3DtGzx7wHAoisrKynrnnXdIdwToAs73ACADsgcAGZA9AMiA7AFABmQPADIgewCQAdkDgAzIHgBkQPYAIAOyBwAZkD0AyIDsAUAGZA8AMiB7AJAB2QOADMgeAGRA9gAgA7IHABmQPQDIgOwBQAZkDwAyIHsAkAHZA4AMyB4AZED2ACADsgcAGZA9AMiA7AFABmQPADIgewCQAdkDgAzIHgBkQPYAIAPqzpqTVatWFRUVMS8fPXpka2srFArplxwO58yZM8OGDSPUO6AdC9IdAFoYPXr0kSNHVKc0Nzcz/x4zZgwEz4zAMac5WbFiBUVRfc7icDirV682bqnfhBUAACAASURBVHfAK4FjTjMzZcqUW7du9d5rFEXdv39/xIgRJDoFdAG/e2Zm1apVbDa7x0QWizV9+nQInnmB7JkZmUzW3d3dYyKLxVq1ahWR/gCdQfbMjL29/axZs3r89GGMFy1aRKpLQDeQPfOzcuVK1fM9Npv9xz/+0d7enmCXgA4ge+YnODjYwuLfN4cwxitWrCDYH6AbyJ75kUgkc+fOZeJnYWERGBhItktAB5A9s7RixYquri6EkIWFRVBQkEQiId0joDXInln6y1/+Qj9K1tXVtXz5ctLdAbqA7JklPp8fHByMEBKJRH/+859JdwfoQm/Pc9bU1Fy9elVfrYEBubi4IISmTp168uRJ0n15jbi6uvr4+OinLawnWVlZ+ukQACZs8eLF+oqMnv+OAb9mT4dSFJWVlfXOO+8Q+fSEhIRPPvmk9yNmehESEoIQOn78uCEaN1P0NtEXON8zY5GRkQYKHjACyJ4ZU73DDswOZA8AMiB7AJAB2QOADMgeAGSQzN66devEYjFFUbdv3ybYDUZ3d3dycrKvr69BPyU/P9/Kyur06dMG/RTju3DhQlRU1IkTJzw8PCiKoihq5cqVqgv4+/uLxWI2mz127Nhbt24Zs2+JiYleXl4CgUAkEnl5ee3YsUMulyOETp06lZiYSD8Za3wks3f48OFDhw4R7ICq8vLy//qv/9q8ebNCoTDoBw3KW6Cffvppamrqtm3bgoOD79+/L5VKbW1tjx49+sMPPzDLnDt37vjx4wEBAaWlpZMnTzZm9/71r3+999571dXVT5482bVrV2Ji4uLFixFCgYGBfD5/zpw5TU1NxuwPDY45EULol19++eSTTzZs2DBx4kRDf9b8+fObm5sDAgIM1L5SqTT0T3cPn332WWZmZnZ2tlgsZiampqayWKzQ0FDVUQxJ4XK5GzdutLOzs7S0DAkJWbBgwfnz53/77TeE0McffzxhwoR58+a9fPnSyL0inL3+RrwzsgkTJpw4cWL58uU8Ho90X15Venp6fX290T6uoqJix44dO3fu5PP5qtN9fX3Dw8MfP368ZcsWo3WmP7m5uardc3Z2Rgi1trbSL2NjY2/fvp2SkmLkXhk7exjjpKSk0aNH83g8KyurrVu3MrO6urpiYmLc3NwEAsH48ePpB0QPHDggEomEQuHJkyfnzp0rkUhcXFyOHTtGv+Xy5cvTpk0TCoUSiWTcuHH0QXyf7ZiIK1euuLm5URT15ZdfIrVrl5qayufz7e3t169f7+TkxOfzfX19b9y4gRAKCwvjcrmOjo50mxs3bhSJRBRFPX36NDw8PCIiorKykqIoT09PhNDZs2clEklCQoKB1ig1NRVj3Ocf78bHx48aNerw4cMXLlzoPRdjvG/fvjfeeIPH49nY2CxYsODOnTvqtwnS084tLy+3trYePnw4/dLGxmbWrFkpKSnGPh3Q14Oh9FYYcLHo6GiKoj7//PPGxkaFQrF//36EUFFREcZ4y5YtPB4vJyensbFx27ZtLBbr5s2b9FsQQhcvXmxubq6vr585c6ZIJOro6GhtbZVIJImJiUqlsq6ubtGiRQ0NDWra0cQf/vCHCRMmaL7WCKGsrCzNl8cYP3r0CCGUlpbGbJA+1w5jHBoaKhKJysrK2traSktLp06dKhaLq6urMcbLly93cHBg2kxKSkII0asfHBwslUqZWWfOnBGLxXFxcVp1EmO8ePFiTZ4b9vDwGDNmTI+JUqn0wYMHGOOrV6+yWKwRI0a0trZijAsKCoKCguhlYmJiuFzukSNHmpqaiouLJ0+ePHTo0Lq6OvXb5FV2bkdHR01NTVpaGo/HO3LkiOqsqKgo5nv46ttEQ0bNnkKhEAqFb7/9NjOF/v+sqKhIqVQKhUKZTMYsyePxPvjgA/z7nlAqlfQsOq4VFRW//vorQujMmTOqH6GmHU2Qyl7vtcMYh4aGWllZMW+8efMmQmjnzp1Ym+zpTJPvWWtrK0VRAQEBPaYz2cMYR0REIIQ+/PBDrJI9hUJhaWnJ7CaM8U8//YQQov+P6G+bvOLOdXBwQAjZ2tp+8cUXdJIZX3/9NULo22+/Vd+CfrNn1GPOiooKhUIxZ86c3rPu3r2rUCi8vb3plwKBwNHRkT4I6YHL5SKEOjs7PTw87O3tV6xYERsb+/DhQ23bMU3M2vWeNWXKFKFQaFLrUl9fjzFmirH0KT4+fvTo0fv3779y5QozsbS0tLW1dcqUKcyUqVOncrlc+qC6B2abvOLOffToUX19/ffff//NN99MmjRJ9ayYXoUnT55o2JReGDV7NTU1CCE7O7ves168eIEQ2r59O/W7qqoq9Zf7BQLBpUuX/Pz8EhISPDw8ZDKZUqnUoR0zwuPxGhoaSPfi39ra2hBC6i9Q8fn8jIwMiqLWrl2rVCrpifQ1fUtLS9Ulra2tW1pa1DT1ijuXw+HY2dn5+/tnZmaWlpbu3r2bmSUQCJjVMRqjZo++1tTe3t57Fh3I5ORk1R/la9euqW9w7Nixp0+frq2tjYyMzMrK2rt3r27tmIXOzs6mpib6z9VNBP2VHfDetI+Pz+bNm8vLy3ft2kVPsba2Rgj1SNqAa6evnevp6clms0tLS5kpHR0dzOoYjVGz5+3tzWKxLl++3HuWq6srn8/X6gGX2trasrIyhJCdnd2ePXsmT55cVlamQzvmorCwEGM8ffp0hJCFhUWfx6VGZm9vT1GUJnfwdu3a5eXlxRQP9Pb2trS0/Pnnn5kFbty40dHR8eabb6ppRLed++zZs2XLlqlOKS8v7+rqcnV1ZabQq0CfEBqNUbNnZ2cXHByck5OTnp4ul8uLi4sPHjxIz+Lz+WvWrDl27NiBAwfkcnlXV1dNTQ1997M/tbW169evv3PnTkdHR1FRUVVV1fTp03Vox5R1d3c3Nja+fPmyuLg4PDzczc2NLvTl6en5/PnzvLy8zs7OhoaGqqoq5i1Dhgypra19+PBhS0tLZ2dnQUGB4e4xCIVCDw8P+lRCPfrIk/lLXz6fHxERkZube/ToUblcXlJSsmHDBicnp9DQUPWN9LdzZTKZg4NDn4+qiUSic+fOXbp0SS6Xd3Z2FhUVvfvuuyKRaPPmzcwy9CqMGzdOq9V/Vfq6aKPhPYaWlpZ169bZ2tpaWlr6+fnFxMQghFxcXH755Zf29vbIyEg3NzcLCws6paWlpfv376fPg0eOHFlZWXnw4EF6LMrhw4efP3/e19fXxsaGzWYPGzYsOjr65cuXGOM+21Hfq2vXrs2YMcPJyYneJo6Ojr6+vpcvXx5wdZCW1znT0tLo+3JCoTAwMFDN2t27dy80NJTD4Tg7O1tYWEgkkgULFlRWVtLtPHv27K233uLz+e7u7h999BF9m9TT07O6uvrWrVvDhw8XCAR+fn51dXX5+flisTg+Pl7zTtI0vKYXFhbG4XAUCgX9Mjc3VyqVIoSGDh1KX9tUtXXrVuYeQ3d3d1JS0siRIzkcjo2NzcKFC+/evYsxVr9N+tu5CxcuRAjFxMT02cnAwEB3d3dLS0sejyeVSmUyWUlJieoC8+fPd3Z27u7u1ss20ZCxszfIaJs9rYSGhg4ZMsRAjQ9Iw+9ZeXm5hYVFj9tlxtfV1TVz5sz09HQd3vv06VM+n793794BlzTjewxAW6Qesdecp6dnXFxcXFwc84iW8XV1deXl5bW0tMhkMh3eHhsbO3HixLCwML13TL3XInt37tyh+qfbDgOMqKiokJAQmUxG6rHpwsLCEydOFBQUqL/T2Kd9+/bdvn07Pz+fw+EYom9qvBbZ8/LyUvPTn5mZSbqDfdi2bVtGRkZzc7O7u3tOTg7p7gwgISEhLCxsz549RD59zpw53333HfOAq+ZOnjzZ3t5eWFhoY2NjiI6pBwNdmajdu3er3vw1ff7+/v7+/qR7oZ2goKCgoCBSn/5a/O4BYIIgewCQAdkDgAzIHgBk6Plai36LRZiF5OTkQVkw5Pr16+i13KFqXL9+nX6eVi/gdw8AMvT8uzcofwHUoChq06ZNpGqAGRTUAOsNaoABMBhA9gAgA7IHABmQPQDIgOwBQAb57KlWrqFxuVx7e/vZs2cnJSU1NjaS7iDQiCnXIYqPj+/xh2P0QIOvbx0iGlO5hh4Htru7u76+Pjs7293dPTIycuzYsaoj6gDTZOJ1iPoDdYj+A0VR1tbWs2fPzsjIyM7OfvLkCV24h3S/jE0v5YSMU5PI9OsQIYR6jGpBD2qOXuc6ROotXrx49erV9fX1X331Fem+GJteygkZoSaRWdQhUu91qUOkLXpIvIKCAmS2hYpwPwV3NC8nZMo1icyxDlEPr0sdov4w53s90GlxdXXFplGoqAekwThlagruaF7SxPg1iQZTHaJdu3a5uLhYW1tzOJwRI0YEBQX99NNPqgsM/jpEavSXPYwxfQZoIoWKehgwe+oL7miVPSPXJBpMdYjoYUtbWlra29uvXbs2adIkgUDw66+/MgsM/jpEOnjx4gXGWCKRmGmhIq0K7mjORGoSmUsdIldX10mTJllaWnK53OnTp2dkZCiVSjrStMFfh0gH9+7dQwh5eXmZaaEi3QruaMIUahKZVx0ixrhx49hsNv3Vog3+OkQ6OHv2LEJo7ty5ZlqoSLeCOwMykZpEZlqHqLu7u7u7W/W/jMFfh0hbdXV1ycnJLi4ua9euNdNCReoL7uhcTshEahKZRR0ihNCf/vQn1Zf05RkfHx9myuCvQ6Qexri1tZWuR9HQ0JCVlTVjxgw2m52XlyeRSMy0UJH6gjualxNCJlmTyCzqECGEHj9+nJmZ2dTU1NnZee3atXXr1rm5uW3YsIFZ4LWoQ9TbqVOnxo8fLxQKuVwui8VCvz/aMm3atLi4uGfPnjFLEixU1B+kwT2G/gruYG3KCRm/JtFgqkMUEREhlUpFIpGFhYWLi8t7771XW1urugDUITI/mmRPL4xfkwjqEPX2et1jAAzTrEkEdYh0BtkDrwrqEOkGsmcGTL8mEdQh0gHUITIDZlGTCOoQaQt+9wAgA7IHABmQPQDIgOwBQAZkDwBC9HWT3tAjLwBgCvT4XAuF9TRGRU1NzdWrV/XSFNDQkiVLwsPDVZ/HB4bm6uqqrw2ut+wB46MoKisra1BWIHsdwPkeAGRA9gAgA7IHABmQPQDIgOwBQAZkDwAyIHsAkAHZA4AMyB4AZED2ACADsgcAGZA9AMiA7AFABmQPADIgewCQAdkDgAzIHgBkQPYAIAOyBwAZkD0AyIDsAUAGZA8AMiB7AJAB2QOADMgeAGRA9gAgA7IHABmQPQDIgOwBQAZkDwAyIHsAkAHZA4AMC9IdAFqoqqrq6upSnfLkyZP79+8zL4cNG8bn843eL6ALqDtrTubPn5+fn9/fXA6H8+TJExsbG2N2CegMjjnNiUwm628Wi8Xy9/eH4JkRyJ45WbRoUX+HlBjjlStXGrk/4FVA9syJSCT6y1/+wuFwes/i8Xh/+ctfjN8loDPInplZvnz5y5cve0zkcDiLFi0SiUREugR0A9kzM/PmzbO0tOwxsbOzc/ny5UT6A3QG2TMzXC43JCSEy+WqTpRIJH/84x9JdQnoBrJnfpYtW9bR0cG85HA4S5cu7ZFGYPrg/p756e7udnR0bGhoYKZcvnz5v/7rvwh2CegAfvfMD4vFWr58OXO1087Ozs/Pj2yXgA4ge2Zp6dKlnZ2dCCEul7t69WoWC/aj+YFjTrOEMR4xYkR1dTVC6Oeff37zzTdJ9whoDf6/NEsURa1atQoh5OHhAcEzU3r7O4Zr167t27dPX62BAcnlcoQQn88PCQkh3ZfXiI+Pz+bNm/XSlN5+9x49epSTk6Ov1sxFTk5OTU0NkY+WSCTW1taurq4Gav/69evXr183UONm6vr169euXdNXa3r++73jx4/rt0ETR1HUpk2b3nnnHSKffuHCBcPdUqd/Tl+3Haqefg8x4HzPjMGzLGYNsgcAGZA9AMiA7AFABmQPADJIZm/dunVisZiiqNu3bxPsBkIoLi5uzJgxEomEx+N5enr+9a9/bW1tNdBn5efnW1lZnT592kDtk3LhwoWoqKgTJ054eHhQFEVRVI8xLPz9/cViMZvNHjt27K1bt4zZt/j4eOo/eXt7I4ROnTqVmJjYY+g3oyGZvcOHDx86dIhgBxiXLl368MMPHz58+PTp0927d6ekpBjuhvWgfIjv008/TU1N3bZtW3Bw8P3796VSqa2t7dGjR3/44QdmmXPnzh0/fjwgIKC0tHTy5MkEe8sIDAzk8/lz5sxpamoy/qfDMSdCCFlaWoaGhg4ZMkQsFr/zzjsLFy48e/bso0ePDPFZ8+fPb25uDggIMETjCCGlUunr62ugxvv02WefZWZmZmdni8ViZmJqaiqLxQoNDW1ubjZmZ/pz5MgRrOLXX3+lp3/88ccTJkyYN29e75E4DI1w9iiKItsB2pkzZ9hsNvNy6NChCCGFQkGuR7pLT0+vr6832sdVVFTs2LFj586dPQZQ8/X1DQ8Pf/z48ZYtW4zWGd3Exsbevn07JSXFyJ9r7OxhjJOSkkaPHs3j8aysrLZu3crM6urqiomJcXNzEwgE48ePz8rKQggdOHBAJBIJhcKTJ0/OnTtXIpG4uLgcO3aMfsvly5enTZsmFAolEsm4cePoRxz7bEcrjx8/FggE7u7uelrpf7ty5YqbmxtFUV9++SVSu3apqal8Pt/e3n79+vVOTk58Pt/X1/fGjRsIobCwMC6X6+joSLe5ceNGkUhEUdTTp0/Dw8MjIiIqKyspivL09EQInT17ViKRJCQk6H1daKmpqRjjwMDA3rPi4+NHjRp1+PDhCxcu9J6LMd63b98bb7zB4/FsbGwWLFhw584d9dsE6WPn9mZjYzNr1qyUlBRjnw5gPaG3woCLRUdHUxT1+eefNzY2KhSK/fv3I4SKioowxlu2bOHxeDk5OY2Njdu2bWOxWDdv3qTfghC6ePFic3NzfX39zJkzRSJRR0dHa2urRCJJTExUKpV1dXWLFi1qaGhQ046GXrx4IRaLw8LCNFkYIZSVlaV54xhj+lA2LS2N2SB9rh3GODQ0VCQSlZWVtbW1lZaWTp06VSwWV1dXY4yXL1/u4ODAtJmUlIQQolc/ODhYKpUys86cOSMWi+Pi4rTqJMZ48eLFixcvHnAxDw+PMWPG9JgolUofPHiAMb569SqLxRoxYkRrayvGuKCgICgoiF4mJiaGy+UeOXKkqampuLh48uTJQ4cOraurU79NdNu5u3btcnFxsba25nA4I0aMCAoK+umnn1QXiIqKYr6Hr75NNGTU7CkUCqFQ+PbbbzNT6P/PioqKlEqlUCiUyWTMkjwe74MPPsC/7wmlUknPouNaUVFBH7KfOXNG9SPUtKOh6OjoUaNGyeVyTRbWV/Z6rx3GODQ01MrKinnjzZs3EUI7d+7E2mRPZ5p8z1pbWymKCggI6DGdyR7GOCIiAiH04YcfYpXsKRQKS0tLZjdhjH/66SeEEP1/RH/bROedW11dfevWrZaWlvb29mvXrk2aNEkgEPz666/MAl9//TVC6Ntvv1Xfjn6zZ9RjzoqKCoVCMWfOnN6z7t69q1Ao6Cu/CCGBQODo6EgfhPRADwrU2dnp4eFhb2+/YsWK2NjYhw8fattOn3Jzc7Ozs3/88UfVywbGxKxd71lTpkwRCoWar4sR1NfXY4yFQqGaZeLj40ePHr1///4rV64wE0tLS1tbW6dMmcJMmTp1KpfLpQ+qe2C2ic4719XVddKkSZaWllwud/r06RkZGUqlko40jV6FJ0+eDNiUHhk1e/Sf29jZ2fWe9eLFC4TQ9u3bmTswVVVV6q92CASCS5cu+fn5JSQkeHh4yGQypVKpQzuMzMzMzz77rLCwcMSIETqsnRHweDzVIZKIa2trQwjxeDw1y/D5/IyMDIqi1q5dq1Qq6Yn0Nf0eA41aW1u3tLSoaepVdq6qcePGsdnse/fuMVMEAgGzOkZj1OzRl8La29t7z6IDmZycrPqjPODfSo0dO/b06dO1tbWRkZFZWVl79+7VrR2EUFpa2tGjRy9dujRs2DBd1s3wOjs7m5qaXFxcSHfk3+iv7ID3pum/Ny0vL9+1axc9xdraGiHUI2kDrp3OO7eH7u7u7u5u1f8y6DEX6dUxGqNmz9vbm8ViXb58ufcsV1dXPp+v1QMutbW1ZWVlCCE7O7s9e/ZMnjy5rKxMh3YwxpGRkSUlJXl5eb2HfDYdhYWFGOPp06cjhCwsLPo8LjUye3t7iqI0uYO3a9cuLy+voqIi+qW3t7elpeXPP//MLHDjxo2Ojg7141/osHNpf/rTn1Rf0pdnfHx8mCn0Kjg4OGjb8qswavbs7OyCg4NzcnLS09PlcnlxcfHBgwfpWXw+f82aNceOHTtw4IBcLu/q6qqpqfntt9/UtFZbW7t+/fo7d+50dHQUFRVVVVVNnz5dh3bKysr+9re/HTp0iMPhqD52tHfvXn2uvE66u7sbGxtfvnxZXFwcHh7u5ua2evVqhJCnp+fz58/z8vI6OzsbGhqqqqqYtwwZMqS2tvbhw4ctLS2dnZ0FBQWGu8cgFAo9PDw0+ct9+siTuYnK5/MjIiJyc3OPHj0ql8tLSko2bNjg5OQUGhqqvpH+dq5MJnNwcOjvUbXHjx9nZmY2NTV1dnZeu3Zt3bp1bm5uGzZsYBagV2HcuHGar7se6OuijYb3GFpaWtatW2dra2tpaenn5xcTE4MQcnFx+eWXX9rb2yMjI93c3CwsLOiUlpaW7t+/nz4PHjlyZGVl5cGDByUSCUJo+PDh58+f9/X1tbGxYbPZw4YNi46OfvnyJca4z3bUdKmkpKTPLZOUlDTg6iAtr3OmpaXR9+WEQmFgYKCatbt3715oaCiHw3F2drawsJBIJAsWLKisrKTbefbs2VtvvcXn893d3T/66CP6Nqmnpyd9QW/48OECgcDPz6+uri4/P18sFsfHx2veSZqG1/TCwsI4HI5CoaBf5ubmSqVShNDQoUPpa5uqtm7dytxj6O7uTkpKGjlyJIfDsbGxWbhw4d27dzHG6rdJfzt34cKFCKGYmJg+OxkRESGVSkUikYWFhYuLy3vvvVdbW6u6wPz5852dnbu7u/WyTTRk7OwNMtpmTyv0Y24GanxAGn7PysvLLSwsejyxZXxdXV0zZ85MT0/X4b1Pnz7l8/l79+4dcEkzvscAtEXqEXvNeXp6xsXFxcXFGe4vPwbU1dWVl5fX0tKipi6vGrGxsRMnTgwLC9N7x9R7LbJ3584dqn+67TDAiIqKCgkJkclkpB6bLiwsPHHiREFBgfo7jX3at2/f7du38/Pz+6woalCvRfa8vLzU/PRnZmaS7mAftm3blpGR0dzc7O7ubvqDLyYkJISFhe3Zs4fIp8+ZM+e7775jHnDV3MmTJ9vb2wsLC4nUqdfzGIFAX3bv3r17927SvdCCv7+/v78/6V5oJygoKCgoiNSnvxa/ewCYIMgeAGRA9gAgA7IHABmQPQAI0ddNer389T4AJk6Pz7Xo+R7D65bAJUuWhIeHqz4RP2gkJycjhDZt2kS6IyaE3ib6oufskaqGRcqSJUt8fHwG5VrT1b8G5arpTL8V0eB8DwAyIHsAkAHZA4AMyB4AZED2ACCDfPZUq0bRuFyuvb397Nmzk5KSGhsbSXcQaMSUa4AlJiZ6eXkJBAKRSOTl5bVjxw66fADZGmCmMmaEVCqlx2CmRwf6xz/+sXr1aoqinJyctBrR3ciQIceMIEur8RFiYmICAgKYwbzpGmCo16jhqmPCG9P8+fP37t1bX1/f0tKSnZ3N4XCYwdFTUlJmzZrV2NioSTuDfMwIiqKsra1nz56dkZGRnZ395MkTumgW6X4Zm15KeRmnHpjp1wDjcrkbN260s7OztLQMCQlZsGDB+fPn6QHOXt8aYOotXrx49erV9fX1X331Fem+GJteSnkZoR6YWdQAy83NVe2es7MzQogZYOZ1qQGmLXo4yoKCAmRKRcK0gvspdqV5KS9TrgdmjjXAysvLra2thw8fTr98XWqA9Yc53+uBTourqys2mSJhqpAG53tqil1pXk7I+PXABlMNMFpHR0dNTU1aWhqPx+sxqOHgrwGmRn/ZwxjTZ4CmUyRM1YDZU1/sSqvsGbke2GCqAUajh3y3tbX94osv6CQzBn8NMB28ePECYyyRSEykSJi2tCp2pTkTqQdmLjXAaI8ePaqvr//++++/+eabSZMmqZ4JD/4aYDqgCzV5eXmZQpEwHehW7EoTplAPzLxqgHE4HDs7O39//8zMzNLSUtVh4AZ/DTAdnD17FiE0d+5c4kXCdKNbsasBmUg9MDOtAebp6clms0tLS5kpg78GmLbq6uqSk5NdXFzWrl1LsEjYq1Bf7ErnUl4mUg/MLGqAPXv2bNmyZapTysvLu7q6XF1dmSmDvwaYehjj1tZWuhZMQ0NDVlbWjBkz2Gx2Xl6eRCIhWCTsVagvdqV5KS9kkvXAzKIGmEgkOnfu3KVLl+RyeWdnZ1FR0bvvvisSiTZv3sws81rUAOvt1KlT48ePFwqFXC6XxWKh3x9tmTZtWlxc3LNnz5glSRUJUwNpcI+hv2JXWJtSXsavBzaYaoAFBga6u7tbWlryeDypVCqTyUpKSlQXgBpg5keT7OmF8euBQQ2w3l6vewyAYZr1wKAGmM4ge+BVQQ0w3UD2zIDp1wODGmA6gBpgZsAs6oFBDTBtwe8eAGRA9gAgA7IHABmQPQDI0PO1luzsbP02aPoM9xw2WfRjVq/hDlWjpqZGn8+v6+sm/etWgQi8nvT4XAuFjTxGBdAfiqKysrKgVJCZgvM9AMiA7AFABmQPADIgewCQAdkDgAzIHgBkQPYAIAOyBwAZkD0AyIDsAUAGZA8AMiB7AJAB2QOADMgeAGRA9gAgA7IHABmQPQDIgOwBQAZkDwAyIHsA+nFciAAAEAdJREFUkAHZA4AMyB4AZED2ACADsgcAGZA9AMiA7AFABmQPADIgewCQAdkDgAzIHgBkQPYAIAOyBwAZkD0AyNBzvXVgUIcOHXr+/LnqlJMnTz548IB5uWbNGnt7e6P3C+gCaj6bk/Xr1//973/n8Xi9Z3V2dtrY2NTV1VlYwP+n5gGOOc3J0qVLEULtfWGz2cuWLYPgmRH43TMnGGNnZ+fffvutz7lXr1718fExcpeAzuB3z5xQFLV8+XIul9t71rBhw6ZPn278LgGdQfbMzNKlSzs6OnpM5HK57777LkVRRLoEdAPHnOZn5MiRFRUVPSYWFxePGzeOSH+AbuB3z/ysWLGCw+GoTvH09ITgmR3InvlZsWLFy5cvmZccDmfNmjUE+wN0A8ecZmnixInFxcX0vqMoqrKy0t3dnXSngHbgd88srVq1is1mI4QoinrzzTcheOYIsmeWli5d2t3djRBis9mrVq0i3R2gC8ieWXJycpoxYwZFUd3d3SEhIaS7A3QB2TNXK1euxBjPnj3b0dGRdF+ATrCeZGVlkV4VAAxu8eLF+oqMnh+9fd0SuGTJkvDwcFJPUSYnJ7///vsikchAjSOENm3aZIjGzRS9TfRFz9l755139NugiVuyZImPjw+ptfbz8xs2bJiBGj9+/Dh6/XaoevQ20Rc43zNjhgseMALIHgBkQPYAIAOyBwAZkD0AyCCZvXXr1onFYoqibt++TbAbCKHExEQvLy+BQCASiby8vHbs2CGXyw30Wfn5+VZWVqdPnzZQ+6RcuHAhKirqxIkTHh4eFEVRFLVy5UrVBfz9/cViMZvNHjt27K1bt4zZt/7276lTpxITE7u6uozZGQbJ7B0+fPjQoUMEO8D417/+9d5771VXVz958mTXrl2JiYmLFy820GfhwfiHI59++mlqauq2bduCg4Pv378vlUptbW2PHj36ww8/MMucO3fu+PHjAQEBpaWlkydPNmb3+tu/gYGBfD5/zpw5TU1NxuwPDY45EUKIy+Vu3LjRzs7O0tIyJCRkwYIF58+f729Iolc0f/785ubmgIAAQzSOEFIqlb6+vgZqvE+fffZZZmZmdna2WCxmJqamprJYrNDQ0ObmZmN2pk9q9u/HH388YcKEefPmqf5JpHEQzp6JDDGSm5vL5/OZl87Ozgih1tZWcj3SXXp6en19vdE+rqKiYseOHTt37lTdgAghX1/f8PDwx48fb9myxWid6Y/6/RsbG3v79u2UlBQj98rY2cMYJyUljR49msfjWVlZbd26lZnV1dUVExPj5uYmEAjGjx9PP5524MABkUgkFApPnjw5d+5ciUTi4uJy7Ngx+i2XL1+eNm2aUCiUSCTjxo2jD+L7bEcr5eXl1tbWw4cP19NK/9uVK1fc3Nwoivryyy+R2rVLTU3l8/n29vbr1693cnLi8/m+vr43btxACIWFhXG5XOYR6o0bN4pEIoqinj59Gh4eHhERUVlZSVGUp6cnQujs2bMSiSQhIUHv60JLTU3FGAcGBvaeFR8fP2rUqMOHD1+4cKH3XIzxvn373njjDR6PZ2Njs2DBgjt37qjfJkgfOxf12r82NjazZs1KSUkx9umAvh4MpbfCgItFR0dTFPX55583NjYqFIr9+/cjhIqKijDGW7Zs4fF4OTk5jY2N27ZtY7FYN2/epN+CELp48WJzc3N9ff3MmTNFIlFHR0dra6tEIklMTFQqlXV1dYsWLWpoaFDTzoA6OjpqamrS0tJ4PN6RI0c0eQtCKCsrS5MlGY8ePUIIpaWlMRukz7XDGIeGhopEorKysra2ttLS0qlTp4rF4urqaozx8uXLHRwcmDaTkpIQQvTqBwcHS6VSZtaZM2fEYnFcXJxWncQYL168WJPnhj08PMaMGdNjolQqffDgAcb46tWrLBZrxIgRra2tGOOCgoKgoCB6mZiYGC6Xe+TIkaampuLi4smTJw8dOrSurk79NtF552K1+zcqKor5Hr76NtGQUbOnUCiEQuHbb7/NTKH/PysqKlIqlUKhUCaTMUvyeLwPPvgA/74nlEolPYuOa0VFxa+//ooQOnPmjOpHqGlnQA4ODgghW1vbL774gt7TA9JX9nqvHcY4NDTUysqKeePNmzcRQjt37sTaZE9nmnzPWltbKYoKCAjoMZ3JHsY4IiICIfThhx9ilewpFApLS0tmN2GMf/rpJ4QQ/X9Ef9vkVXYuVrt/v/76a4TQt99+q74F/WbPqMecFRUVCoVizpw5vWfdvXtXoVB4e3vTLwUCgaOjI30Q0gM9MmxnZ6eHh4e9vf2KFStiY2MfPnyobTu9PXr0qL6+/vvvv//mm28mTZpkzLMmBrN2vWdNmTJFKBRquC7GUV9fjzEWCoVqlomPjx89evT+/fuvXLnCTCwtLW1tbZ0yZQozZerUqVwulz6o7oHZJq+yc5Ha/UuvwpMnTzRsSi+Mmr2amhqEkJ2dXe9ZL168QAht376d+l1VVZVCoVDTmkAguHTpkp+fX0JCgoeHh0wmUyqVOrTD4HA4dnZ2/v7+mZmZpaWlu3fv1mUlDYnH4zU0NJDuxb+1tbUhhPqszcLg8/kZGRkURa1du1apVNIT6Wv6lpaWqktaW1u3tLSoaepVdi5Su38FAgGzOkZj1OzR15ra29t7z6IDmZycrPqjfO3aNfUNjh079vTp07W1tZGRkVlZWXv37tWtnR48PT3ZbHZpaalW7zK0zs7OpqYmFxcX0h35N/orO+C9aR8fn82bN5eXl+/atYueYm1tjRDqkbQB104vOxf1tX/pob7p1TEao2bP29ubxWJdvny59yxXV1c+n6/VAy61tbVlZWUIITs7uz179kyePLmsrEyHdp49e7Zs2TLVKeXl5V1dXa6urpo3YgSFhYUYY7rogoWFRZ/HpUZmb29PUZQmd/B27drl5eVVVFREv/T29ra0tPz555+ZBW7cuNHR0fHmm2+qaUSHnYs027/0KtAnhEZj1OzZ2dkFBwfn5OSkp6fL5fLi4uKDBw/Ss/h8/po1a44dO3bgwAG5XN7V1VVTU6P+7nZtbe369evv3LnT0dFRVFRUVVU1ffp0HdoRiUTnzp27dOmSXC7v7OwsKip69913RSLR5s2b9bnyOunu7m5sbHz58mVxcXF4eLibm9vq1asRQp6ens+fP8/Ly+vs7GxoaKiqqmLeMmTIkNra2ocPH7a0tHR2dhYUFBjuHoNQKPTw8KBPJdSjjzzpcQ3plxEREbm5uUePHpXL5SUlJRs2bHBycgoNDVXfSH87VyaTOTg49Pmomib7l14FY4/tra+LNhreY2hpaVm3bp2tra2lpaWfn19MTAxCyMXF5Zdffmlvb4+MjHRzc7OwsKBTWlpaun//fvo8eOTIkZWVlQcPHpRIJAih4cOHnz9/3tfX18bGhs1mDxs2LDo6+uXLlxjjPttR36vAwEB3d3dLS0sejyeVSmUyWUlJiSZrjbS8zpmWlkbflxMKhYGBgWrW7t69e6GhoRwOx9nZ2cLCQiKRLFiwoLKykm7n2bNnb731Fp/Pd3d3/+ijj+jbpJ6entXV1bdu3Ro+fLhAIPDz86urq8vPzxeLxfHx8Zp3kqbhNb2wsDAOh6NQKOiXubm5UqkUITR06FD62qaqrVu3MvcYuru7k5KSRo4cyeFwbGxsFi5cePfuXYyx+m3S385duHAhQigmJqbPTg64f+fPn+/s7Nzd3a2XbaIhY2dvkNE2e1oJDQ0dMmSIgRofkIbfs/LycgsLCw1vhxpOV1fXzJkz09PTdXjv06dP+Xz+3r17B1zSjO8xAG2ResRec56ennFxcXFxcQQfwevq6srLy2tpaZHJZDq8PTY2duLEiWFhYXrvmHqvRfbu3LlD9U+3HQYYUVFRISEhMpmM1GPThYWFJ06cKCgoUH+nsU/79u27fft2fn5+j9JORvBaZM/Ly0vNT39mZibpDvZh27ZtGRkZzc3N7u7uOTk5pLszgISEhLCwsD179hD59Dlz5nz33Xc6jBF88uTJ9vb2wsJCGxsbQ3RMPT2PEQj0Zffu3SZ4c18Nf39/f39/0r3QTlBQUFBQEKlPfy1+9wAwQZA9AMiA7AFABmQPADL0fK0lOztbvw2aPh2e5TUL9GNWr+EOVaOmpkafz7Lr6yb961aBCLyeTLcGGB6MA+CpQVFUVlbWoCzWQ5ez1W/lHXOn3xK/cL4HABmQPQDIgOwBQAZkDwAyIHsAkAHZA4AM8tlTrRpF43K59vb2s2fPTkpKamxsJN1BoBFTrgFG6+7uTk5OVi0UQ7YGmKmMGSGVSukxmOnRgf7xj3+sXr2aoignJyfNB/02PmTIMSPI0mp8hJiYmICAALlcTr+ka4ChXqOGq44Jb2T37t2bMWMGQmjChAmq01NSUmbNmtXY2KhJI4N8zAiKoqytrWfPnp2RkZGdnf3kyRO6aBbpfhmbXkp5GacemOnXAPvll18++eSTDRs2TJw4sces17cGmHqLFy9evXp1fX39V199RbovxqaXUl5GqAdmFjXAJkyYcOLEieXLl/c5hPbrUgNMW/RwlAUFBciUioRpBfdT7ErzUl6mXA/MHGuA9fC61ADrD3O+1wOdFldXV2wCRcJ6Qxqc76kpdqV5OSHj1wMbfDXAMMZ/+MMfepzv0YjUADP13z2xWExRVEtLS1tb24EDBxYuXBgcHGxtbb19+3YOh5ORkcEs6evrK5FI7OzsZDLZixcvqqurHz58KJfLx44dy+fzHRwcTpw4MXTo0AHb0S+lUrlv375FixatWLHCyspq3LhxX3311dOnT5kBuTVnYWFB/0qMGTPmwIEDLS0t2nZ7/vz5crl8x44d2n50f168ePHgwQN6MNw++fj4bNq06eHDh5988onqdE02S+8darh9N3LkSIRQSUnJqzelOVPP3osXLzDGEonEFIqE6UCrYleaM5F6YOZVA0yNwV8DTAf37t1DCHl5eZlCkTAd6FbsShOmUA/MvGqAqTH4a4Dp4OzZswihuXPnmlSRMM3pVuxqQCZSD8xMa4D1NvhrgGmrrq4uOTnZxcVl7dq1BIuEvQr1xa50LuVlIvXAzKIGmCYGfw0w9TDGra2tdC2YhoaGrKysGTNmsNnsvLw8iURCsEjYq1Bf7ErzUl7IJOuBmUUNME28FjXAejt16tT48eOFQiGXy2WxWOj3R1umTZsWFxf37NkzZkmCRcL6gzS4x9BfsSusTSkv49cDG0w1wK5duzZjxgwnJyf6O+/o6Ojr63v58mVmAagBZn40yZ5eGL8eGNQA6+31ur8HGKZZDwxqgOkMsgdeFdQA0w1kzwyYfj0wqAGmA6gBZgbMoh4Y1ADTFvzuAUAGZA8AMiB7AJAB2QOADD1fa9FvsQizkJycPCgLhly/fh29ljtUjevXr9PP0OoFhfX0d/LXrl3bt2+fXpoCwGTRf5Ohl6b0lj0AgFbgfA8AMiB7AJAB2QOADMgeAGT8f+YSK0AdAc26AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# implementer fonction de cout et optimizateur\n",
        "model.compile(optimizer = 'SGD', loss = 'binary_crossentropy', metrics =['accuracy'] )"
      ],
      "metadata": {
        "id": "r1vCsjm5JSVo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training model"
      ],
      "metadata": {
        "id": "KwZwQElULbOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=00.2, random_state = 0)"
      ],
      "metadata": {
        "id": "1b7OFWUcLgij"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X_train, y = Y_train, validation_data = (X_test, Y_test),   epochs = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piS6DRYGLU38",
        "outputId": "7932110d-84af-4b30-862d-2c02637129cb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.7401 - accuracy: 0.5000 - val_loss: 0.7392 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7395 - accuracy: 0.5000 - val_loss: 0.7387 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7388 - accuracy: 0.5000 - val_loss: 0.7377 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7377 - accuracy: 0.5000 - val_loss: 0.7363 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7363 - accuracy: 0.5000 - val_loss: 0.7347 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7347 - accuracy: 0.5000 - val_loss: 0.7334 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7338 - accuracy: 0.5000 - val_loss: 0.7333 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7336 - accuracy: 0.5000 - val_loss: 0.7330 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7330 - accuracy: 0.5000 - val_loss: 0.7317 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7318 - accuracy: 0.5000 - val_loss: 0.7305 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7306 - accuracy: 0.5000 - val_loss: 0.7296 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.7297 - accuracy: 0.5000 - val_loss: 0.7287 - val_accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7289 - accuracy: 0.5000 - val_loss: 0.7281 - val_accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.7282 - accuracy: 0.5000 - val_loss: 0.7267 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7268 - accuracy: 0.5000 - val_loss: 0.7259 - val_accuracy: 0.5000\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.7259 - accuracy: 0.5000 - val_loss: 0.7245 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7246 - accuracy: 0.5000 - val_loss: 0.7232 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7233 - accuracy: 0.5000 - val_loss: 0.7222 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7223 - accuracy: 0.5000 - val_loss: 0.7212 - val_accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.7213 - accuracy: 0.5000 - val_loss: 0.7203 - val_accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7203 - accuracy: 0.5000 - val_loss: 0.7196 - val_accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7196 - accuracy: 0.5000 - val_loss: 0.7186 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7188 - accuracy: 0.5000 - val_loss: 0.7182 - val_accuracy: 0.5000\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7184 - accuracy: 0.5000 - val_loss: 0.7178 - val_accuracy: 0.5000\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7179 - accuracy: 0.5000 - val_loss: 0.7172 - val_accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7174 - accuracy: 0.5000 - val_loss: 0.7170 - val_accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7172 - accuracy: 0.5000 - val_loss: 0.7166 - val_accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7167 - accuracy: 0.5000 - val_loss: 0.7155 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7157 - accuracy: 0.5000 - val_loss: 0.7152 - val_accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7152 - accuracy: 0.5000 - val_loss: 0.7144 - val_accuracy: 0.5000\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7144 - accuracy: 0.5000 - val_loss: 0.7138 - val_accuracy: 0.5000\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7139 - accuracy: 0.5000 - val_loss: 0.7132 - val_accuracy: 0.5000\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7134 - accuracy: 0.5000 - val_loss: 0.7129 - val_accuracy: 0.5000\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7129 - accuracy: 0.5000 - val_loss: 0.7121 - val_accuracy: 0.5000\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7123 - accuracy: 0.5000 - val_loss: 0.7118 - val_accuracy: 0.5000\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7119 - accuracy: 0.5000 - val_loss: 0.7113 - val_accuracy: 0.5000\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7114 - accuracy: 0.5000 - val_loss: 0.7103 - val_accuracy: 0.5000\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7104 - accuracy: 0.5000 - val_loss: 0.7099 - val_accuracy: 0.5000\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7099 - accuracy: 0.5000 - val_loss: 0.7094 - val_accuracy: 0.5000\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7095 - accuracy: 0.5000 - val_loss: 0.7089 - val_accuracy: 0.5000\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.7090 - accuracy: 0.5000 - val_loss: 0.7080 - val_accuracy: 0.5000\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7081 - accuracy: 0.5000 - val_loss: 0.7074 - val_accuracy: 0.5000\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.7075 - accuracy: 0.5000 - val_loss: 0.7070 - val_accuracy: 0.5000\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7070 - accuracy: 0.5000 - val_loss: 0.7065 - val_accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7067 - accuracy: 0.5000 - val_loss: 0.7063 - val_accuracy: 0.5000\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.7064 - accuracy: 0.5000 - val_loss: 0.7057 - val_accuracy: 0.5000\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.7058 - accuracy: 0.5000 - val_loss: 0.7048 - val_accuracy: 0.5000\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.7048 - accuracy: 0.5000 - val_loss: 0.7044 - val_accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.7046 - accuracy: 0.5000 - val_loss: 0.7044 - val_accuracy: 0.5000\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7045 - accuracy: 0.5000 - val_loss: 0.7040 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ec815f070>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP regression"
      ],
      "metadata": {
        "id": "D91OPkQkpi7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importation des donnees\n",
        "from sklearn.datasets import fetch_openml\n",
        "load_boston = fetch_openml(name = 'boston')\n",
        "data = load_boston['data']\n",
        "target  = load_boston['target']\n",
        "features = load_boston['feature_names']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh4-qWHRppqs",
        "outputId": "11ee99f5-8f12-4a35-faa1-095ce4a51f40"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:301: UserWarning: Multiple active versions of the dataset matching the name boston exist. Versions may be fundamentally different, returning version 1.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "890tipuiq4I_",
        "outputId": "141ef8f6-712c-4435-eec8-70316c00f380"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CRIM    ZN  INDUS CHAS    NOX     RM   AGE     DIS RAD    TAX  PTRATIO  \\\n",
              "0  0.00632  18.0   2.31    0  0.538  6.575  65.2  4.0900   1  296.0     15.3   \n",
              "1  0.02731   0.0   7.07    0  0.469  6.421  78.9  4.9671   2  242.0     17.8   \n",
              "2  0.02729   0.0   7.07    0  0.469  7.185  61.1  4.9671   2  242.0     17.8   \n",
              "3  0.03237   0.0   2.18    0  0.458  6.998  45.8  6.0622   3  222.0     18.7   \n",
              "4  0.06905   0.0   2.18    0  0.458  7.147  54.2  6.0622   3  222.0     18.7   \n",
              "\n",
              "        B  LSTAT  \n",
              "0  396.90   4.98  \n",
              "1  396.90   9.14  \n",
              "2  392.83   4.03  \n",
              "3  394.63   2.94  \n",
              "4  396.90   5.33  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df9f6bed-9bbc-4617-8539-dd1d335992c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df9f6bed-9bbc-4617-8539-dd1d335992c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df9f6bed-9bbc-4617-8539-dd1d335992c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df9f6bed-9bbc-4617-8539-dd1d335992c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "def model_five_layers(dim_data):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(100, input_dim =dim_data, activation= 'sigmoid', kernel_regularizer= regularizers.l2(0.01))) # coiuche entrees\n",
        "  model.add(Dense(150, activation='relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(100, activation='sigmoid'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(30, activation='sigmoid'))\n",
        "  model.add(Dense(100, activation='sigmoid',kernel_regularizer= regularizers.l2(0.2)))\n",
        "  model.add(Dense(1, activation='linear'))\n",
        "\n",
        "  model.compile(optimizer ='SGD', loss ='mean_squared_error')\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "S81zpr_Bq9jn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_cr = StandardScaler().fit_transform(data)\n",
        "X_train, X_test, Y_train,Y_test = train_test_split(X_cr, target, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "TM7r6Vdhrf1Z"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apprentissage\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "callbacks = [EarlyStopping(monitor ='val_loss', patience = 50 )]\n",
        "model = model_five_layers(X_train.shape[1])\n",
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs = 500,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNFpTkfKRhDJ",
        "outputId": "b21e109e-529a-41c3-cba3-e0cd860dcb96"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "13/13 [==============================] - 1s 19ms/step - loss: 147.7314 - val_loss: 97.1414\n",
            "Epoch 2/500\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 94.3303 - val_loss: 95.1845\n",
            "Epoch 3/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 94.8456 - val_loss: 88.3210\n",
            "Epoch 4/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 92.0171 - val_loss: 92.0192\n",
            "Epoch 5/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 92.3425 - val_loss: 87.0519\n",
            "Epoch 6/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 90.4227 - val_loss: 87.2969\n",
            "Epoch 7/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 90.0698 - val_loss: 82.9026\n",
            "Epoch 8/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 81.0963 - val_loss: 84.7191\n",
            "Epoch 9/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 70.6344 - val_loss: 97.4278\n",
            "Epoch 10/500\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 60.6340 - val_loss: 63.1130\n",
            "Epoch 11/500\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 49.0088 - val_loss: 62.0578\n",
            "Epoch 12/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 41.4655 - val_loss: 51.4020\n",
            "Epoch 13/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 48.7037 - val_loss: 50.9870\n",
            "Epoch 14/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 36.8483 - val_loss: 48.5545\n",
            "Epoch 15/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 39.4610 - val_loss: 50.1995\n",
            "Epoch 16/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 36.4904 - val_loss: 60.5037\n",
            "Epoch 17/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 33.3784 - val_loss: 46.3647\n",
            "Epoch 18/500\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 34.1078 - val_loss: 44.2434\n",
            "Epoch 19/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 31.4613 - val_loss: 43.9266\n",
            "Epoch 20/500\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 33.1276 - val_loss: 54.8240\n",
            "Epoch 21/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 29.5067 - val_loss: 48.6675\n",
            "Epoch 22/500\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 44.4229 - val_loss: 40.0646\n",
            "Epoch 23/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 27.8314 - val_loss: 37.9112\n",
            "Epoch 24/500\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 34.7313 - val_loss: 41.3075\n",
            "Epoch 25/500\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 27.3775 - val_loss: 37.0424\n",
            "Epoch 26/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 30.8977 - val_loss: 52.8696\n",
            "Epoch 27/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 30.2849 - val_loss: 57.3202\n",
            "Epoch 28/500\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 27.2642 - val_loss: 35.6137\n",
            "Epoch 29/500\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 29.6052 - val_loss: 35.2750\n",
            "Epoch 30/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 25.0595 - val_loss: 38.6650\n",
            "Epoch 31/500\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 27.7272 - val_loss: 45.5050\n",
            "Epoch 32/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 25.8403 - val_loss: 34.4075\n",
            "Epoch 33/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 25.7777 - val_loss: 34.6990\n",
            "Epoch 34/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 26.5016 - val_loss: 34.1347\n",
            "Epoch 35/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 21.7737 - val_loss: 32.4660\n",
            "Epoch 36/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 22.6784 - val_loss: 32.0964\n",
            "Epoch 37/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 20.3056 - val_loss: 32.8018\n",
            "Epoch 38/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 20.0968 - val_loss: 34.5334\n",
            "Epoch 39/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 21.8052 - val_loss: 33.4151\n",
            "Epoch 40/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 19.8035 - val_loss: 30.8042\n",
            "Epoch 41/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 19.8166 - val_loss: 33.3526\n",
            "Epoch 42/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 21.6982 - val_loss: 31.9947\n",
            "Epoch 43/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 22.7542 - val_loss: 31.0603\n",
            "Epoch 44/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 19.1051 - val_loss: 32.9907\n",
            "Epoch 45/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 20.9810 - val_loss: 37.6041\n",
            "Epoch 46/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 23.1543 - val_loss: 32.5373\n",
            "Epoch 47/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 18.4402 - val_loss: 34.5437\n",
            "Epoch 48/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 19.9601 - val_loss: 37.7408\n",
            "Epoch 49/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 19.5542 - val_loss: 35.4635\n",
            "Epoch 50/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 19.7699 - val_loss: 36.4533\n",
            "Epoch 51/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 18.1659 - val_loss: 36.5836\n",
            "Epoch 52/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 19.1920 - val_loss: 30.3290\n",
            "Epoch 53/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 18.4102 - val_loss: 39.4526\n",
            "Epoch 54/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 19.7264 - val_loss: 31.7660\n",
            "Epoch 55/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 18.4166 - val_loss: 35.5344\n",
            "Epoch 56/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 19.2044 - val_loss: 30.8321\n",
            "Epoch 57/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 18.0509 - val_loss: 30.3589\n",
            "Epoch 58/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 17.1631 - val_loss: 29.9026\n",
            "Epoch 59/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 18.2617 - val_loss: 32.5752\n",
            "Epoch 60/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 17.8375 - val_loss: 30.0823\n",
            "Epoch 61/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 17.4220 - val_loss: 38.1454\n",
            "Epoch 62/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 18.0416 - val_loss: 32.5613\n",
            "Epoch 63/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 20.6169 - val_loss: 31.1377\n",
            "Epoch 64/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 17.5447 - val_loss: 34.2720\n",
            "Epoch 65/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 20.5952 - val_loss: 29.4322\n",
            "Epoch 66/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 18.2922 - val_loss: 30.3816\n",
            "Epoch 67/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 17.7611 - val_loss: 31.8055\n",
            "Epoch 68/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 16.8129 - val_loss: 31.1295\n",
            "Epoch 69/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 17.5433 - val_loss: 33.4242\n",
            "Epoch 70/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 15.2531 - val_loss: 27.8060\n",
            "Epoch 71/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 16.9814 - val_loss: 29.6024\n",
            "Epoch 72/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 17.2854 - val_loss: 31.4015\n",
            "Epoch 73/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 16.8860 - val_loss: 35.5369\n",
            "Epoch 74/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 17.4051 - val_loss: 30.2206\n",
            "Epoch 75/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 15.9340 - val_loss: 30.9017\n",
            "Epoch 76/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 16.2632 - val_loss: 32.6842\n",
            "Epoch 77/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 18.1425 - val_loss: 36.3043\n",
            "Epoch 78/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 16.9144 - val_loss: 32.4698\n",
            "Epoch 79/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 16.2516 - val_loss: 30.3323\n",
            "Epoch 80/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 18.0941 - val_loss: 31.3554\n",
            "Epoch 81/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 17.1820 - val_loss: 29.4810\n",
            "Epoch 82/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 16.9080 - val_loss: 36.2349\n",
            "Epoch 83/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 16.8331 - val_loss: 29.8925\n",
            "Epoch 84/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 16.3091 - val_loss: 31.2963\n",
            "Epoch 85/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 16.0451 - val_loss: 30.6979\n",
            "Epoch 86/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 16.9659 - val_loss: 28.4055\n",
            "Epoch 87/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 16.9108 - val_loss: 27.6824\n",
            "Epoch 88/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 15.9101 - val_loss: 28.6533\n",
            "Epoch 89/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 16.2574 - val_loss: 27.2525\n",
            "Epoch 90/500\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 17.2249 - val_loss: 31.1151\n",
            "Epoch 91/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 15.7786 - val_loss: 29.9546\n",
            "Epoch 92/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 15.4595 - val_loss: 27.1715\n",
            "Epoch 93/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 16.0821 - val_loss: 33.3535\n",
            "Epoch 94/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 17.1022 - val_loss: 28.7048\n",
            "Epoch 95/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 16.5975 - val_loss: 30.2864\n",
            "Epoch 96/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 14.6097 - val_loss: 28.5172\n",
            "Epoch 97/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 15.1067 - val_loss: 27.7937\n",
            "Epoch 98/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 14.5851 - val_loss: 28.7029\n",
            "Epoch 99/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 14.4285 - val_loss: 29.3550\n",
            "Epoch 100/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 15.8033 - val_loss: 28.5965\n",
            "Epoch 101/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 14.5413 - val_loss: 28.1565\n",
            "Epoch 102/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 17.1994 - val_loss: 27.9340\n",
            "Epoch 103/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 14.9756 - val_loss: 26.4973\n",
            "Epoch 104/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 16.6246 - val_loss: 32.0170\n",
            "Epoch 105/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 16.8105 - val_loss: 37.0000\n",
            "Epoch 106/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 17.1991 - val_loss: 32.6012\n",
            "Epoch 107/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 16.1750 - val_loss: 27.6420\n",
            "Epoch 108/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 15.2072 - val_loss: 28.6350\n",
            "Epoch 109/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 15.4189 - val_loss: 28.9796\n",
            "Epoch 110/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 15.4456 - val_loss: 27.7862\n",
            "Epoch 111/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 14.8125 - val_loss: 30.4322\n",
            "Epoch 112/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 15.6337 - val_loss: 26.3073\n",
            "Epoch 113/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 15.0256 - val_loss: 36.5083\n",
            "Epoch 114/500\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.8697 - val_loss: 30.3813\n",
            "Epoch 115/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 14.4400 - val_loss: 28.3364\n",
            "Epoch 116/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 15.0939 - val_loss: 32.6721\n",
            "Epoch 117/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 16.9660 - val_loss: 27.2290\n",
            "Epoch 118/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 16.6868 - val_loss: 29.5825\n",
            "Epoch 119/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 15.0492 - val_loss: 26.7750\n",
            "Epoch 120/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 14.7230 - val_loss: 28.6164\n",
            "Epoch 121/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 14.8620 - val_loss: 28.2401\n",
            "Epoch 122/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 15.5530 - val_loss: 29.7844\n",
            "Epoch 123/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 16.2460 - val_loss: 32.5655\n",
            "Epoch 124/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 17.3265 - val_loss: 28.0925\n",
            "Epoch 125/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 15.4760 - val_loss: 34.1196\n",
            "Epoch 126/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 15.6696 - val_loss: 27.7100\n",
            "Epoch 127/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 14.6065 - val_loss: 30.0792\n",
            "Epoch 128/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 16.7716 - val_loss: 29.3314\n",
            "Epoch 129/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 14.2352 - val_loss: 28.5873\n",
            "Epoch 130/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 14.6117 - val_loss: 26.7047\n",
            "Epoch 131/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 15.7208 - val_loss: 27.4042\n",
            "Epoch 132/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 16.8896 - val_loss: 26.6709\n",
            "Epoch 133/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 15.1962 - val_loss: 26.9178\n",
            "Epoch 134/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 14.7908 - val_loss: 27.2031\n",
            "Epoch 135/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 14.4638 - val_loss: 28.9223\n",
            "Epoch 136/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 14.9813 - val_loss: 27.2568\n",
            "Epoch 137/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 14.8799 - val_loss: 26.7320\n",
            "Epoch 138/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 14.2040 - val_loss: 26.3539\n",
            "Epoch 139/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 14.1185 - val_loss: 27.9541\n",
            "Epoch 140/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 13.1580 - val_loss: 26.7953\n",
            "Epoch 141/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 14.3592 - val_loss: 27.1787\n",
            "Epoch 142/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 13.8355 - val_loss: 31.0403\n",
            "Epoch 143/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 14.0786 - val_loss: 28.6266\n",
            "Epoch 144/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 15.9529 - val_loss: 29.7276\n",
            "Epoch 145/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 17.7365 - val_loss: 27.0612\n",
            "Epoch 146/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 16.1898 - val_loss: 27.2400\n",
            "Epoch 147/500\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.6720 - val_loss: 31.5663\n",
            "Epoch 148/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 14.2704 - val_loss: 28.6266\n",
            "Epoch 149/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 13.8127 - val_loss: 30.3678\n",
            "Epoch 150/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 14.6026 - val_loss: 27.0559\n",
            "Epoch 151/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 15.0461 - val_loss: 28.4358\n",
            "Epoch 152/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 14.1280 - val_loss: 27.8381\n",
            "Epoch 153/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 14.2804 - val_loss: 28.6604\n",
            "Epoch 154/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.9724 - val_loss: 29.5698\n",
            "Epoch 155/500\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.4991 - val_loss: 28.5326\n",
            "Epoch 156/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.7561 - val_loss: 32.4585\n",
            "Epoch 157/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.9501 - val_loss: 29.3222\n",
            "Epoch 158/500\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.7905 - val_loss: 28.7215\n",
            "Epoch 159/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 15.7670 - val_loss: 26.5809\n",
            "Epoch 160/500\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.6132 - val_loss: 26.7899\n",
            "Epoch 161/500\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.6480 - val_loss: 26.5547\n",
            "Epoch 162/500\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.8719 - val_loss: 27.4688\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc4adcf83a0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics \n",
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(model.predict(X_test), Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJeL7RMlU2xz",
        "outputId": "2a373e6b-8e7c-49d9-98d4-816962527ba6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25.551579449144395"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}